{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI W261: Machine Learning at Scale\n",
    "## Assignment Week 13\n",
    "Miki Seltzer (miki.seltzer@berkeley.edu)<br>\n",
    "W261-2, Spring 2016<br>\n",
    "Submission: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.5.0-cdh5.5.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.11 (default, Dec  6 2015 18:08:32)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "# If running locally, start PySpark\n",
    "import os\n",
    "import sys\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 13.4: Criteo Phase 2 Baseline\n",
    "Using the training dataset, validation dataset and testing dataset in the Criteo bucket perform the following experiment:\n",
    "\n",
    "- Write Spark code (borrow from Phase 1 of this project) to train a logistic regression model with the following hyperparamters:\n",
    "  - Number of buckets for hashing: 1,000\n",
    "  - Logistic Regression: no regularization term\n",
    "  - Logistic Regression: step size = 10\n",
    "  \n",
    "- AWS configuration: 1 master (r3.xlarge), 4 workers (r3.xlarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16']\n"
     ]
    }
   ],
   "source": [
    "rawTrainData = (sc\n",
    "              .textFile('s3://criteo-dataset/rawdata/train')\n",
    "              .map(lambda x: x.replace('\\t', ','))\n",
    "              .cache()\n",
    "               )\n",
    "\n",
    "rawValidationData = (sc\n",
    "                     .textFile('s3://criteo-dataset/rawdata/validation')\n",
    "                     .map(lambda x: x.replace('\\t', ','))\n",
    "                     .cache()\n",
    "                    )\n",
    "\n",
    "rawTestData = (sc\n",
    "               .textFile('s3://criteo-dataset/rawdata/test')\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache()\n",
    "              )\n",
    "\n",
    "print rawTrainData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for ind, category in rawFeats:\n",
    "        featureString = category + str(ind)\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print mapping\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data to convert the string into hashed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (1000,[64,101,117,147,178,215,223,268,304,313,321,328,384,385,442,532,601,613,619,621,628,644,650,655,659,680,681,697,721,738,742,824,846,882,903,924],[1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def parseHashPoint(point, numBuckets):\n",
    "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest are\n",
    "            features.\n",
    "        numBuckets: The number of buckets to hash to.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
    "            features.\n",
    "    \"\"\"\n",
    "    \n",
    "    fields = point.split(',')\n",
    "    label = fields[0]\n",
    "    features = zip(range(len(fields[1:])), fields[1:])\n",
    "    \n",
    "    return LabeledPoint(label, SparseVector(numBuckets, hashFunction(numBuckets, features)))\n",
    "\n",
    "numBucketsCTR = 1000\n",
    "hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashTrainData.cache()\n",
    "\n",
    "print hashTrainData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
    "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        p (float): A probabilty between 0 and 1.\n",
    "        y (int): A label.  Takes on the values 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The log loss value.\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    if p == 0:\n",
    "        prob = epsilon\n",
    "    elif p == 1:\n",
    "        prob = 1 - epsilon\n",
    "    else:\n",
    "        prob = p * 1.\n",
    "    return -(y * log(prob) + (1 - y) * log(1 - prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\"Calculate the probability for an observation given a set of weights and intercept.\n",
    "\n",
    "    Note:\n",
    "        We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "    Args:\n",
    "        x (SparseVector): A vector with values of 1.0 for features that exist in this\n",
    "            observation and 0.0 otherwise.\n",
    "        w (DenseVector): A vector of weights (betas) for the model.\n",
    "        intercept (float): The model's intercept.\n",
    "\n",
    "    Returns:\n",
    "        float: A probability between 0 and 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = x.dot(w) + intercept\n",
    "\n",
    "    # Bound the raw prediction value\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return 1 / (1 + exp(-rawPrediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateResults(model, data):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): A trained logistic regression model.\n",
    "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    return (data\n",
    "            .map(lambda x: computeLogLoss(getP(x.features, model.weights, model.intercept), x.label))\n",
    "            .reduce(lambda x, y: x + y)) / data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with hashed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training with 100 iterations took 408 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "import time\n",
    "\n",
    "# fixed hyperparameters\n",
    "stepSize = 10.\n",
    "regType = None\n",
    "numIters = 100\n",
    "\n",
    "startTime = time.time()\n",
    "model = (LogisticRegressionWithSGD\n",
    "         .train(hashTrainData, iterations=numIters, step=stepSize, regType=regType)\n",
    "        )\n",
    "endTime = time.time()\n",
    "\n",
    "print 'Model training with', numIters, 'iterations took', int(endTime - startTime), 'seconds.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(sc, 's3://ms-w261-hw13/criteo_baseline_100iter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report in tabular form  the logLossTest for the Training, Validation, and Testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: Logloss values for each data set using logistic regression model\n",
      "\n",
      "Data set    Logloss   \n",
      "----------------------\n",
      "Train       0.50505746\n",
      "Validation  0.50526198\n",
      "Test        0.50519185\n"
     ]
    }
   ],
   "source": [
    "logLossTrain = evaluateResults(model, hashTrainData)\n",
    "\n",
    "hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, numBucketsCTR)).cache()\n",
    "logLossVal = evaluateResults(model, hashValidationData)\n",
    "\n",
    "hashTestData = rawTestData.map(lambda x: parseHashPoint(x, numBucketsCTR)).cache()\n",
    "logLossTest = evaluateResults(model, hashTestData)\n",
    "\n",
    "print 'Table 1: Logloss values for each data set using logistic regression model\\n'\n",
    "\n",
    "print '{:12s}{:10s}'.format('Data set', 'Logloss')\n",
    "print '-'*22\n",
    "\n",
    "table1 = '{:12s}{:10.8f}'.format\n",
    "print table1('Train', logLossTrain)\n",
    "print table1('Validation', logLossVal)\n",
    "print table1('Test', logLossTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report in tabular form the AUC value for the Training, Validation, and Testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 2: AUC values for each data set using logistic regression model\n",
      "\n",
      "Data set    AUC       \n",
      "----------------------\n",
      "Train       0.58009052\n",
      "Validation  0.58026576\n",
      "Test        0.58020823\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def getAUC(model, data):\n",
    "    metrics = BinaryClassificationMetrics(data.map(lambda lp: (float(model.predict(lp.features)), lp.label)))\n",
    "    return metrics.areaUnderROC\n",
    "\n",
    "trainAUC = getAUC(model, hashTrainData)\n",
    "valAUC = getAUC(model, hashValidationData)\n",
    "testAUC = getAUC(model, hashTestData)\n",
    "\n",
    "print 'Table 2: AUC values for each data set using logistic regression model\\n'\n",
    "\n",
    "print '{:12s}{:10s}'.format('Data set', 'AUC')\n",
    "print '-'*22\n",
    "\n",
    "table1 = '{:12s}{:10.8f}'.format\n",
    "print table1('Train', trainAUC)\n",
    "print table1('Validation', valAUC)\n",
    "print table1('Test', testAUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 13.5: Criteo Phase 2 Hyperparameter Tuning\n",
    "Experiment with various hyperparameters, including:\n",
    "- Number of hashing buckets (explore values of 1,000 and 10,000 and others)\n",
    "- Regularization term (1e-6, 1e-3 and others)\n",
    "- Step size (start with 1, then others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def getAUC(model, data):\n",
    "    metrics = BinaryClassificationMetrics(data.map(lambda lp: (float(model.predict(lp.features)), lp.label)))\n",
    "    return metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixed hyperparameters\n",
    "numHashBuckets = [100, 1000, 10000]\n",
    "regType = 'l2'\n",
    "regParams = [1e-6, 1e-3, 1e-1]\n",
    "stepSizes = [10, 1, 0.1]\n",
    "numIters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hashBuckets  regParam  stepSize trainTime    LL_val\n",
      "-----------------------------------------------------------------------------------\n",
      "          100     1e-06      10.0       984   1.82397\n",
      "          100     1e-06       1.0        41   0.54596\n",
      "          100     1e-06       0.1        41   0.56565\n",
      "          100     1e-03      10.0        39   2.11433\n",
      "          100     1e-03       1.0        40   0.54599\n",
      "          100     1e-03       0.1        42   0.56565\n",
      "          100     1e-01      10.0        40   3.65541\n",
      "          100     1e-01       1.0        41   0.54905\n",
      "          100     1e-01       0.1        41   0.56599\n",
      "         1000     1e-06      10.0      1049   0.75516\n",
      "         1000     1e-06       1.0        52   0.54177\n",
      "         1000     1e-06       0.1        52   0.58065\n",
      "         1000     1e-03      10.0        48   0.83817\n",
      "         1000     1e-03       1.0        49   0.54181\n",
      "         1000     1e-03       0.1        49   0.58067\n",
      "         1000     1e-01      10.0        48   1.26079\n",
      "         1000     1e-01       1.0        48   0.54629\n",
      "         1000     1e-01       0.1        42   0.58186\n",
      "        10000     1e-06      10.0      1049   0.62033\n",
      "        10000     1e-06       1.0        49   0.54115\n",
      "        10000     1e-06       0.1        48   0.58662\n",
      "        10000     1e-03      10.0        47   0.59876\n",
      "        10000     1e-03       1.0        48   0.54120\n",
      "        10000     1e-03       0.1        49   0.58664\n",
      "        10000     1e-01      10.0        48   0.96734\n",
      "        10000     1e-01       1.0        48   0.54593\n",
      "        10000     1e-01       0.1        49   0.58792\n"
     ]
    }
   ],
   "source": [
    "bestModel = None\n",
    "bestLogloss = 1e9\n",
    "\n",
    "print ('{:>13s}{:>10s}{:>10s}{:>10s}{:>10s}'\n",
    "       .format('hashBuckets', 'regParam', 'stepSize', 'trainTime', 'LL_val'))\n",
    "print '-'*53\n",
    "\n",
    "for h in numHashBuckets:\n",
    "    # Create hashed feature RDDs\n",
    "    hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, h)).cache()\n",
    "    hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, h)).cache()\n",
    "    \n",
    "    for r in regParams:\n",
    "        for s in stepSizes:\n",
    "            startTime = time.time()\n",
    "            model1 = (LogisticRegressionWithSGD\n",
    "                      .train(hashTrainData, iterations=numIters, step=s, regType=regType, regParam=r)\n",
    "                     )\n",
    "            endTime = time.time()\n",
    "    \n",
    "            valLL = evaluateResults(model1, hashValidationData)\n",
    "        \n",
    "            print ('{:13d}{:10.0e}{:10.1f}{:10d}{:10.5f}'\n",
    "                   .format(h, r, s, int(endTime - startTime), valLL))\n",
    "            \n",
    "            if valLL < bestLogloss:\n",
    "                bestModel = model1\n",
    "                bestLogloss = valLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestModel.save(sc, 's3://ms-w261-hw13/criteo_bestModel1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like having 10,000 buckets consistently produces lower logloss values, let's stick with that number. We'll get more granular with the regularization parameters, and zoom in on stepSizes centered on 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixed hyperparameters\n",
    "h = 10000\n",
    "regParams = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "stepSizes = [5, 1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hashBuckets  regParam  stepSize trainTime    LL_val\n",
      "-----------------------------------------------------\n",
      "        10000     1e-06       5.0        48   0.53819\n",
      "        10000     1e-06       1.0        48   0.54115\n",
      "        10000     1e-06       0.5        48   0.55176\n",
      "        10000     1e-05       5.0        49   0.53820\n",
      "        10000     1e-05       1.0        49   0.54115\n",
      "        10000     1e-05       0.5        48   0.55176\n",
      "        10000     1e-04       5.0        47   0.53826\n",
      "        10000     1e-04       1.0        48   0.54116\n",
      "        10000     1e-04       0.5        48   0.55176\n",
      "        10000     1e-03       5.0        48   0.53883\n",
      "        10000     1e-03       1.0        48   0.54120\n",
      "        10000     1e-03       0.5        49   0.55177\n",
      "        10000     1e-02       5.0        49   0.54752\n",
      "        10000     1e-02       1.0        48   0.54162\n",
      "        10000     1e-02       0.5        48   0.55194\n",
      "        10000     1e-01       5.0        48   0.58471\n",
      "        10000     1e-01       1.0        48   0.54593\n",
      "        10000     1e-01       0.5        48   0.55389\n"
     ]
    }
   ],
   "source": [
    "bestModel2 = None\n",
    "bestLogloss2 = 1e9\n",
    "\n",
    "logLosses = []\n",
    "AUCs = []\n",
    "\n",
    "print ('{:>13s}{:>10s}{:>10s}{:>10s}{:>10s}'\n",
    "       .format('hashBuckets', 'regParam', 'stepSize', 'trainTime', 'LL_val'))\n",
    "print '-'*53\n",
    "    \n",
    "for r in regParams:\n",
    "    for s in stepSizes:\n",
    "        startTime = time.time()\n",
    "        model2 = (LogisticRegressionWithSGD\n",
    "                  .train(hashTrainData, iterations=numIters, step=s, regType=regType, regParam=r)\n",
    "                 )\n",
    "        endTime = time.time()\n",
    "\n",
    "        valLL = evaluateResults(model2, hashValidationData)\n",
    "        valAUC = getAUC(model2, hashValidationData)\n",
    "\n",
    "        logLosses.append([r, s, valLL])\n",
    "        AUCs.append([r, s, valAUC])\n",
    "        \n",
    "        print ('{:13d}{:10.0e}{:10.1f}{:10d}{:10.5f}'\n",
    "               .format(h, r, s, int(endTime - startTime), valLL))\n",
    "\n",
    "        if valLL < bestLogloss2:\n",
    "            bestModel2 = model2\n",
    "            bestLogloss2 = valLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1e-06, 5, 0.5381945595699974], [1e-06, 1, 0.5411535575705866], [1e-06, 0.5, 0.5517564699843335], [1e-05, 5, 0.5382000828365382], [1e-05, 1, 0.5411539714508792], [1e-05, 0.5, 0.5517566304915823], [0.0001, 5, 0.5382554892006085], [0.0001, 1, 0.5411581105158698], [0.0001, 0.5, 0.5517582359285195], [0.001, 5, 0.5388282611574104], [0.001, 1, 0.5411995272488614], [0.001, 0.5, 0.5517743266845319], [0.01, 5, 0.5475238092617305], [0.01, 1, 0.5416161822138278], [0.01, 0.5, 0.5519388154658781], [0.1, 5, 0.5847096063714977], [0.1, 1, 0.5459317073016486], [0.1, 0.5, 0.5538896516404738]]\n",
      "[[1e-06, 5, 0.6213779310550208], [1e-06, 1, 0.49999970672534505], [1e-06, 0.5, 0.5], [1e-05, 5, 0.6213781662142314], [1e-05, 1, 0.49999970672534505], [1e-05, 0.5, 0.5], [0.0001, 5, 0.621389655604656], [0.0001, 1, 0.49999970672534505], [0.0001, 0.5, 0.5], [0.001, 5, 0.6215083080101218], [0.001, 1, 0.49999970672534505], [0.001, 0.5, 0.5], [0.01, 5, 0.624681753311662], [0.01, 1, 0.49999970672534505], [0.01, 0.5, 0.5], [0.1, 5, 0.5], [0.1, 1, 0.5], [0.1, 0.5, 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print logLosses\n",
    "print AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestModel2.save(sc, 's3://ms-w261-hw13/criteo_bestModel2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
