{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI W261: Machine Learning at Scale\n",
    "## Assignment Week 13\n",
    "Miki Seltzer (miki.seltzer@berkeley.edu)<br>\n",
    "W261-2, Spring 2016<br>\n",
    "Submission: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.5.0-cdh5.5.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.11 (default, Dec  6 2015 18:08:32)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "# If running locally, start PySpark\n",
    "import os\n",
    "import sys\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 13.4: Criteo Phase 2 Baseline\n",
    "Using the training dataset, validation dataset and testing dataset in the Criteo bucket perform the following experiment:\n",
    "\n",
    "- Write spark code (borrow from Phase 1 of this project) to train a logistic regression model with the following hyperparamters:\n",
    "  - Number of buckets for hashing: 1,000\n",
    "  - Logistic Regression: no regularization term\n",
    "  - Logistic Regression: step size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16']\n"
     ]
    }
   ],
   "source": [
    "rawTrainData = (sc\n",
    "              .textFile('s3://criteo-dataset/rawdata/train')\n",
    "              .map(lambda x: x.replace('\\t', ','))\n",
    "              .cache()\n",
    "             )\n",
    "rawValidationData = (sc\n",
    "                     .textFile('s3://criteo-dataset/rawdata/validation')\n",
    "                     .map(lambda x: x.replace('\\t', ','))\n",
    "                     .cache()\n",
    "                    )\n",
    "rawTestData = (sc\n",
    "               .textFile('s3://criteo-dataset/rawdata/test')\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache()\n",
    "              )\n",
    "\n",
    "print rawTrainData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for ind, category in rawFeats:\n",
    "        featureString = category + str(ind)\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print mapping\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data to convert the string into hashed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (1000,[64,101,117,147,178,215,223,268,304,313,321,328,384,385,442,532,601,613,619,621,628,644,650,655,659,680,681,697,721,738,742,824,846,882,903,924],[1.0,1.0,2.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def parseHashPoint(point, numBuckets):\n",
    "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest are\n",
    "            features.\n",
    "        numBuckets: The number of buckets to hash to.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
    "            features.\n",
    "    \"\"\"\n",
    "    \n",
    "    fields = point.split(',')\n",
    "    label = fields[0]\n",
    "    features = zip(range(len(fields[1:])), fields[1:])\n",
    "    \n",
    "    return LabeledPoint(label, SparseVector(numBuckets, hashFunction(numBuckets, features)))\n",
    "\n",
    "numBucketsCTR = 1000\n",
    "hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashTrainData.cache()\n",
    "\n",
    "print hashTrainData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
    "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        p (float): A probabilty between 0 and 1.\n",
    "        y (int): A label.  Takes on the values 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The log loss value.\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    if p == 0:\n",
    "        prob = epsilon\n",
    "    elif p == 1:\n",
    "        prob = 1 - epsilon\n",
    "    else:\n",
    "        prob = p * 1.\n",
    "    return -(y * log(prob) + (1 - y) * log(1 - prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\"Calculate the probability for an observation given a set of weights and intercept.\n",
    "\n",
    "    Note:\n",
    "        We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "    Args:\n",
    "        x (SparseVector): A vector with values of 1.0 for features that exist in this\n",
    "            observation and 0.0 otherwise.\n",
    "        w (DenseVector): A vector of weights (betas) for the model.\n",
    "        intercept (float): The model's intercept.\n",
    "\n",
    "    Returns:\n",
    "        float: A probability between 0 and 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = x.dot(w) + intercept\n",
    "\n",
    "    # Bound the raw prediction value\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return 1 / (1 + exp(-rawPrediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateResults(model, data):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): A trained logistic regression model.\n",
    "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    return (data\n",
    "            .map(lambda x: computeLogLoss(getP(x.features, model.weights, model.intercept), x.label))\n",
    "            .reduce(lambda x, y: x + y)) / data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with hashed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training with 5 iterations took 578 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "import time\n",
    "\n",
    "# fixed hyperparameters\n",
    "stepSize = 10.\n",
    "regType = None\n",
    "numIters = 5\n",
    "\n",
    "startTime = time.time()\n",
    "model = (LogisticRegressionWithSGD\n",
    "         .train(hashTrainData, iterations=numIters, step=stepSize, regType=regType)\n",
    "        )\n",
    "endTime = time.time()\n",
    "\n",
    "print 'Model training with', numIters, 'iterations took', int(endTime - startTime), 'seconds.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set    Logloss   \n",
      "----------------------\n",
      "Train       0.48997141\n",
      "Validation  0.49458504\n",
      "Test        0.49517179\n"
     ]
    }
   ],
   "source": [
    "logLossTrain = evaluateResults(model, hashTrainData)\n",
    "\n",
    "hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, numBucketsCTR)).cache()\n",
    "logLossVal = evaluateResults(model, hashValidationData)\n",
    "\n",
    "hashTestData = rawTestData.map(lambda x: parseHashPoint(x, numBucketsCTR)).cache()\n",
    "logLossTest = evaluateResults(model, hashTestData)\n",
    "\n",
    "print '{:12s}{:10s}'.format('Data set', 'Logloss')\n",
    "print '-'*22\n",
    "\n",
    "table1 = '{:12s}{:10.8f}'.format\n",
    "print table1('Train', logLossTrain)\n",
    "print table1('Validation', logLossVal)\n",
    "print table1('Test', logLossTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set    AUC       \n",
      "----------------------\n",
      "Train       0.58609171\n",
      "Validation  0.58040403\n",
      "Test        0.58546408\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def getAUC(data):\n",
    "    metrics = BinaryClassificationMetrics(data.map(lambda lp: (float(model.predict(lp.features)), lp.label)))\n",
    "    return metrics.areaUnderROC\n",
    "\n",
    "trainAUC = getAUC(hashTrainData)\n",
    "valAUC = getAUC(hashValidationData)\n",
    "testAUC = getAUC(hashTestData)\n",
    "\n",
    "print '{:12s}{:10s}'.format('Data set', 'AUC')\n",
    "print '-'*22\n",
    "\n",
    "table1 = '{:12s}{:10.8f}'.format\n",
    "print table1('Train', trainAUC)\n",
    "print table1('Validation', valAUC)\n",
    "print table1('Test', testAUC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
