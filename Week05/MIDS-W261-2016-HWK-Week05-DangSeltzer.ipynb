{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Students**: Miki Seltzer (miki.seltzer@berkeley.edu), Minhchau Dang (minhchau.dang@berkeley.edu)\n",
    "* **Course**: 2016-0111 DATASCI W261: Machine Learning at Scale\n",
    "* **Section**: Spring 2016, Section 2\n",
    "* **Assignment**: Homework 5, Week 5\n",
    "* **Submission Date**: February 18, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires some nbextensions.\n",
    "\n",
    "* [toc2](https://github.com/ipython-contrib/IPython-notebook-extensions/tree/master/nbextensions/usability/toc2) provides a button to create a floating table of contents\n",
    "* [toggle_all_line_numbers](https://github.com/ipython-contrib/IPython-notebook-extensions/tree/master/nbextensions/usability/toggle_all_line_numbers) provides a button to see line numbers for all code cells\n",
    "* [autosaveclasses](https://github.com/holatuwol/jupyter-magic/tree/master/nbextensions/autosaveclasses.js) avoids usage of `%%writefile` (cells with a class definition are saved to disk when run)\n",
    "\n",
    "If they are not yet installed, run the following cell and restart the notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p .local/share/jupyter/nbextensions/\n",
    "\n",
    "nbextdl() {\n",
    "    mkdir -p $(ipython locate)/nbextensions/$(dirname $2)\n",
    "    curl --silent -L \\\n",
    "        \"https://raw.githubusercontent.com/$1/master/nbextensions/$2\" \\\n",
    "        > \"$(ipython locate)/nbextensions/$2\"\n",
    "}\n",
    "\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2/main.js\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2/main.css\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2/icon.png\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2/image.png\n",
    "\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toggle_all_line_numbers/main.js\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toggle_all_line_numbers/icon.png\n",
    "\n",
    "nbextdl holatuwol/jupyter-magic autosaveclasses.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoload the extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['base/js/utils'], function(utils) {\n",
       "    utils.load_extensions('usability/toc2/main');\n",
       "    utils.load_extensions('usability/toggle_all_line_numbers/main');\n",
       "    utils.load_extensions('autosaveclasses');\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'], function(utils) {\n",
    "    utils.load_extensions('usability/toc2/main');\n",
    "    utils.load_extensions('usability/toggle_all_line_numbers/main');\n",
    "    utils.load_extensions('autosaveclasses');\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the HDFS base folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs_base_folder = '/tmp'\n",
    "runner = 'hadoop'\n",
    "\n",
    "mapper_count = 10\n",
    "reducer_count = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is a data warehouse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data warehouse is an enterprise data repository containing various sources of data, ranging from relational databases (such as sales transaction data) to semi-structured data files (such as logs) used for business intelligence and data science.\n",
    "\n",
    "Data warehouses traditionally deal with high volume and high variety, but they are fed by various data pipelines in batch processes in order to support online analytics processing (OLAP) and so are not often high velocity like online transactions processing (OLTP) systems. This pipeline is depicted in an image from [datawarehouse4u.info](http://datawarehouse4u.info/).\n",
    "\n",
    "![Data Warehouse Architecture](http://datawarehouse4u.info/images/data_warehouse_architecture.jpg)\n",
    "\n",
    "Data warehouses have traditionally been used to feed dashboards and reports, but as business intelligence tools evolve, these systems are becoming more interactive with drill-down features such as pivot tables and data cubes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is a Star schema? When is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A star schema is a schema that relates a large fact table (the star schema) with multiple dimension tables (tables that contain the actual information, similar to what is used as measures in pivot tables). This relationship between fact tables and information schemas is depicted in an image in an old [knowledge base article](https://www-01.ibm.com/support/knowledgecenter/SSEPEK_10.0.0/com.ibm.db2z10.doc.perf/src/tpc/db2z_starschemaaccess.dita) for the IBM DB2 database.\n",
    "\n",
    "![Star Schema](https://www-01.ibm.com/support/knowledgecenter/api/content/nl/en-us/SSEPEK_10.0.0/com.ibm.db2z10.doc.perf/src/art/bkn9p039.gif)\n",
    "\n",
    "A star schema is used to organize the metadata of a relational database and facilitate joins of tables by providing information on which tables can be joined with which keys. They are applied when a query joining multiple tables must be materialized. Their design and application makes them similar to snowflake schemas, but star schemas are denormalized whereas snowflake schemas are normalized.\n",
    "\n",
    "Multiple star schemas linked together (by sharing dimension tables) is known as a fact constellation, as described in the first lecture in [CSE 592 at Washington University](https://courses.cs.washington.edu/courses/cse592/01sp/lectures/).\n",
    "\n",
    "![Fact Constellation](https://courses.cs.washington.edu/courses/cse592/01sp/lectures/class1/img033.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the database world, what is 3NF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3NF is shorthand for third normal form. To further summarize [A Simple Guide to Five Normal Forms in Relational Database Theory](http://www.bkent.net/Doc/simple5.htm) by William Kent, a table is in third normal form if the following conditions hold:\n",
    "\n",
    "* All records must contain the same number of fields (first normal form)\n",
    "* If the table is described with a composite key, information in a column relates to the entire the key and not just one of the columns in the key (second normal form)\n",
    "* The value column only provides more information relating directly relating to the key, and there is no transitive dependence between non-key columns in the table (third normal form)\n",
    "\n",
    "The process of converting a non-conforming table into a conforming table is referred to as normalization. One normalization process is depicted in a training slides for the [Geographic Information Technology Training Alliance](http://www.gitta.info/LogicModelin/en/html/DataConsiten_Norm3NF.html).\n",
    "\n",
    "![3NF Normalization](http://www.gitta.info/LogicModelin/en/image/3NF.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Does machine learning use data in 3NF? If so why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML may pull data from data warehouses that have relational databases managed by DBAs concerned with 3NF, but using such a data source is not required by ML.\n",
    "\n",
    "It is desirable to use a 3NF data source because it can save a significant amount of disk space because data duplication is avoided. Additionally, when data is denormalized, then fields in the data set might be related to each other and create record update dependencies. This may be problematic if we are using algorithms that rely on consistent data and feature independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In what form does ML consume data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML requires examining many features and attributes that are potentially stored across a variety of systems. In this examination, ML ultimately consumes any data that can be provided by a data warehouse. As described in a slide from a presentation at a [cognitive computing meetup](http://www.slideshare.net/SaiDevulapalli/machine-learning-use-cases-in-telecom), this means that ML data sources are extremely diverse and ML may wind up looking at data stored in a wide variety of formats.\n",
    "\n",
    "![Data Sources and Use Cases](http://image.slidesharecdn.com/cognitivemeetupjul2014saislidesver2-140717075405-phpapp01/95/machine-learning-use-cases-in-telecom-cognitive-computing-meetup-4-638.jpg?cb=1405583739)\n",
    "\n",
    "In other words, ML may consume data that is in 3NF but it also consumes data on denormalized views resulting from joins of 3NF normalized tables or even data that is not normalized at all. However, since it's looking at a variety of features at once, the easiest way for ML to ingest data in a parallel way is for it to already be denormalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why would one use log files that are denormalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the algorithms, ML algorithms perform better if the data is already prepared in what the ML system perceives to be a single data source, even if the data is actually originating from multiple systems. One way to achieve that is through a log system architecture described in a blog by Jay Kreps from LinkedIn titled [The Log: What every software engineer should know about real-time data's unifying abstraction](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying).\n",
    "\n",
    "Another reason is to treat the data as schema on read rather than schema on write, allowing ML to ingest mostly raw logs before they have been transformed. As noted in the async lectures, this provides analytics tools with the flexibility difference of using ELT rather than ETL processes, though potentially with a slight performance penalty.\n",
    "\n",
    "Additionally, if one needs to perform real-time analysis on log files, it may be too time consuming to join normalized log data in one log table with normalized log data in other tables. If log files are denormalized, they may not need any further processing (joins) to be fed into other steps of a pipeline, thus improving performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using MRJob, implement a hashside join (memory-backed map-side) for left,\n",
    "right and inner joins. Run your code on the  data used in HW 4.4.\n",
    "\n",
    "> (Recall HW 4.4: Find the most frequent visitor of each page using mrjob and the output of 4.2  (i.e., transformed log file). In this output please include the webpage URL, webpageID and Visitor ID.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 4.4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget --quiet https://www.dropbox.com/sh/m0nxsf4vs5cyrp2/AADCHtrJ4CBCDO1po_OAWg0ia/anonymous-msweb.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform 4.4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/tmp/anonymous-msweb.data.visitor': File exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from csv import reader\n",
    "\n",
    "input_file_name = 'anonymous-msweb.data'\n",
    "\n",
    "visitor_file_name = input_file_name + '.visitor'\n",
    "visitor_file = open(visitor_file_name, 'w')\n",
    "\n",
    "webpage_file_name = input_file_name + '.webpage'\n",
    "webpage_file = open(webpage_file_name, 'w')\n",
    "\n",
    "with open(input_file_name) as input_file:\n",
    "    case_id = None\n",
    "\n",
    "    # Update the case ID when we see a new case (line with a C).\n",
    "    # Output the vote when we see a new vote (line with a V).\n",
    "    # Add the 'A' lines to the web page file.\n",
    "\n",
    "    for row in reader(input_file):\n",
    "        if row[0] == 'A':\n",
    "            print >> webpage_file, ','.join(row)\n",
    "            continue\n",
    "\n",
    "        if row[0] == 'C':\n",
    "            case_id = row[1]\n",
    "            continue\n",
    "\n",
    "        if row[0] == 'V':\n",
    "            row.extend(['C', case_id])\n",
    "            print >> visitor_file, ','.join(row)\n",
    "\n",
    "visitor_file.close()\n",
    "webpage_file.close()\n",
    "\n",
    "!hdfs dfs -copyFromLocal $visitor_file_name $hdfs_base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5.2 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "class WebPageHashJoin(MRJob):\n",
    "\n",
    "    \"\"\"\n",
    "    Allow join type to be passed through as a configuration option.\n",
    "    \"\"\"\n",
    "    def configure_options(self):\n",
    "        super(WebPageHashJoin, self).configure_options()\n",
    "        self.add_passthrough_option('--join-type', type = 'string', default = 'left')\n",
    "\n",
    "    \"\"\"\n",
    "    Load the web page data into memory to be the left table.\n",
    "    \"\"\"\n",
    "    def mapper_init(self):\n",
    "        self.vroot_data = {}\n",
    "        self.seen_vroots = set()\n",
    "\n",
    "        with open('anonymous-msweb.data.webpage', 'r') as webpage_file:\n",
    "            for row in csv.reader(webpage_file):\n",
    "                if len(row) != 5:\n",
    "                    continue\n",
    "\n",
    "                vroot_id = row[1]\n",
    "                vroot_datum = [row[0]] + row[2:]\n",
    "                self.vroot_data[vroot_id] = vroot_datum\n",
    "\n",
    "    \"\"\"\n",
    "    Mapper for outer joins which only yields the join result if both results are\n",
    "    not None.\n",
    "    \"\"\"\n",
    "    def mapper_inner_join(self, _, line):\n",
    "        vroot_id, left_result, right_result = self.get_join_row(line)\n",
    "\n",
    "        if left_result is not None and right_result is not None:\n",
    "            yield vroot_id, (left_result, right_result)\n",
    "\n",
    "    \"\"\"\n",
    "    Mapper for outer joins which always yields the join result.\n",
    "    \"\"\"\n",
    "    def mapper_outer_join(self, _, line):\n",
    "        vroot_id, left_result, right_result = self.get_join_row(line)\n",
    "\n",
    "        self.seen_vroots.add(vroot_id)\n",
    "\n",
    "        yield vroot_id, (left_result, right_result)\n",
    "\n",
    "    \"\"\"\n",
    "    Look up the web page data based on the vroot and combine with row.\n",
    "    \"\"\"\n",
    "    def get_join_row(self, line):\n",
    "        row = csv.reader([line]).next()\n",
    "\n",
    "        vroot_id = row[1]\n",
    "\n",
    "        if vroot_id in self.vroot_data:\n",
    "            vroot_datum = self.vroot_data[vroot_id]\n",
    "        else:\n",
    "            vroot_datum = None\n",
    "\n",
    "        visit_datum = [row[0]] + row[2:]\n",
    "\n",
    "        return vroot_id, vroot_datum, visit_datum\n",
    "\n",
    "    \"\"\"\n",
    "    Mapper finalizer which ensures that all values for the left table are emitted.\n",
    "    Should only be used with a left outer join.\n",
    "    \"\"\"\n",
    "    def mapper_final_left_join(self):\n",
    "        for vroot_id, vroot_datum in self.vroot_data.iteritems():\n",
    "            if vroot_id in self.seen_vroots:\n",
    "                continue\n",
    "\n",
    "            yield vroot_id, (vroot_datum, None)\n",
    "\n",
    "    \"\"\"\n",
    "    Reducer finds the most frequent visitor for the given vroot.\n",
    "    \"\"\"\n",
    "    def reducer(self, vroot_id, join_rows):\n",
    "        none_row = None\n",
    "        regular_row = False\n",
    "\n",
    "        # Emit any non-none rows, because none rows could come from multiple reducers\n",
    "        # and might not be valid output.\n",
    "\n",
    "        for join_row in join_rows:\n",
    "            if join_row[0] is None or join_row[1] is None:\n",
    "                none_row = join_row\n",
    "                continue\n",
    "\n",
    "            regular_row = True\n",
    "            yield vroot_id, join_row\n",
    "\n",
    "        # If we never found a non-none row, then emit the none row.\n",
    "\n",
    "        if not regular_row:\n",
    "            yield vroot_id, none_row\n",
    "\n",
    "    \"\"\"\n",
    "    Build out different steps depending on the join type.\n",
    "    \"\"\"\n",
    "    def steps(self):\n",
    "        # Inner join just needs the hash join initialization and uses the\n",
    "        # inner join mapper.\n",
    "\n",
    "        if self.options.join_type == 'inner':\n",
    "            step = MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper_inner_join,\n",
    "                reducer = self.reducer)\n",
    "\n",
    "        # Left join needs to emit keys at the end for anything that was not\n",
    "        # seen in the input and uses the outer join mapper.\n",
    "\n",
    "        elif self.options.join_type == 'left':\n",
    "            step = MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper_outer_join,\n",
    "                mapper_final = self.mapper_final_left_join,\n",
    "                reducer = self.reducer)\n",
    "\n",
    "        # Right join just needs the hash join initialization and otherwise\n",
    "        # uses the outer join mapper.\n",
    "\n",
    "        else:\n",
    "            step = MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper_outer_join,\n",
    "                reducer = self.reducer)\n",
    "\n",
    "        return [step]\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    WebPageHashJoin().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Justify which table you chose as the Left table in this hashside join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the web page table as the left table in this mapper-side hash join because it was the smaller of the two tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please report the number of rows resulting from:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a utility function to report the row counts by using `wc` on the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_join_row_count(join_type):\n",
    "    problem_id = 'mrjob_52_' + join_type\n",
    "    mrjob_status_file = 'mrjob_52_' + join_type + '_progress.txt'\n",
    "\n",
    "    !python WebPageHashJoin.py -r local \\\n",
    "        --hadoop-version=2.7.1 \\\n",
    "        --strict-protocols \\\n",
    "        --join-type=$join_type \\\n",
    "        --output-dir=$hdfs_base_folder/$problem_id \\\n",
    "        --no-output \\\n",
    "        --file anonymous-msweb.data.webpage \\\n",
    "        anonymous-msweb.data.visitor \\\n",
    "        > $mrjob_status_file 2>&1\n",
    "\n",
    "    !wc -l $hdfs_base_folder/$problem_id/* | tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1) Left joining Table Left with Table Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  98663 total\n",
      "CPU times: user 218 ms, sys: 30.2 ms, total: 248 ms\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%time report_join_row_count('left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (2) Right joining Table Left with Table Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  98654 total\n",
      "CPU times: user 143 ms, sys: 24 ms, total: 167 ms\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%time report_join_row_count('right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (3) Inner joining Table Left with Table Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  98654 total\n",
      "CPU times: user 27.3 ms, sys: 6.34 ms, total: 33.6 ms\n",
      "Wall time: 9.84 s\n"
     ]
    }
   ],
   "source": [
    "%time report_join_row_count('inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ngrams data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A large subset of the Google n-grams dataset\n",
    "\n",
    "> https://aws.amazon.com/datasets/google-books-ngrams/\n",
    "\n",
    "> which we have placed in a bucket/folder on Dropbox on s3:\n",
    "\n",
    "> * https://www.dropbox.com/sh/tmqpc4o0xswhkvz/AACUifrl6wrMrlK6a3X3lZ9Ea?dl=0\n",
    "> * s3://filtered-5grams/\n",
    "\n",
    "> This bucket contains (~200) files (10Meg each) in the format:\n",
    "\n",
    "> ```\n",
    "    (ngram) \\t (count) \\t (pages_count) \\t (books_count)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Download the ngrams data set.\n",
    "\n",
    "if not os.path.isdir('ngrams'):\n",
    "    !mkdir ngrams\n",
    "    !aws s3 sync --quiet s3://filtered-5grams/ ngrams/\n",
    "    !hdfs dfs -copyFromLocal ngrams $hdfs_base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create first10 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HW 5.3-5.5, for the Google n-grams dataset unit test and regression test your code using the\n",
    "first 10 lines of the following file:\n",
    "\n",
    "    googlebooks-eng-all-5gram-20090715-0-filtered.txt\n",
    "\n",
    "Once you are happy with your test results proceed to generating your results on the Google n-grams dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use the first 10 lines of the first file for unit testing.\n",
    "\n",
    "if not os.path.isdir('first10'):\n",
    "    !mkdir first10\n",
    "    !head -10 ngrams/googlebooks-eng-all-5gram-20090715-0-filtered.txt > first10/test.txt\n",
    "    !hdfs dfs -copyFromLocal first10 $hdfs_base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set switch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_job(python_args, problem_id, data_set, input_folder):\n",
    "\n",
    "    # Use the notebook variables\n",
    "\n",
    "    global runner\n",
    "    global hdfs_base_folder\n",
    "\n",
    "    # Determine the input folder based on job type\n",
    "\n",
    "    if runner == 'hadoop':\n",
    "        input_folder = 'hdfs://' + hdfs_base_folder + '/' + input_folder\n",
    "\n",
    "    # Create a new output folder for each problem + data set pair\n",
    "\n",
    "    if runner == 'hadoop':\n",
    "        !hdfs dfs -mkdir -p $hdfs_base_folder/$problem_id\n",
    "        !hdfs dfs -rm -r -f -skipTrash $hdfs_base_folder/$problem_id/$data_set > /dev/null\n",
    "    else:\n",
    "        !mkdir -p $hdfs_base_folder/$problem_id\n",
    "        !rm -rf $hdfs_base_folder/$problem_id/$data_set\n",
    "\n",
    "    # Run the program\n",
    "\n",
    "    mrjob_status_file = problem_id + '_progress.txt'\n",
    "\n",
    "    !python $python_args \\\n",
    "        -r $runner \\\n",
    "        --hadoop-version=2.7.1 \\\n",
    "        --strict-protocols \\\n",
    "        --output-dir=$hdfs_base_folder/$problem_id/$data_set \\\n",
    "        --no-output \\\n",
    "        --jobconf mapreduce.job.maps=$mapper_count \\\n",
    "        --jobconf mapreduce.job.reduces=$reducer_count \\\n",
    "        $input_folder \\\n",
    "        > $mrjob_status_file 2>&1\n",
    "\n",
    "def save_job_output(problem_id, data_set, file_name):\n",
    "\n",
    "    # Use the notebook variables\n",
    "\n",
    "    global hdfs_base_folder\n",
    "\n",
    "    # Print the desired output\n",
    "\n",
    "    if runner == 'hadoop':\n",
    "        !hdfs dfs -cat $hdfs_base_folder/$problem_id/$data_set/* > $file_name\n",
    "    elif runner == 'local':\n",
    "        !cat $hdfs_base_folder/$problem_id/$data_set/* > $file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do some EDA on this dataset using mrjob: Longest 5-gram (number of characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing data exploration, we can avoid the single reducer problem as well as the strange Hadoop combiner sort bug by emitting one value per reducer and then doing a simple sort of the output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5.3.1 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import RawProtocol\n",
    "\n",
    "class LongestNGram(MRJob):\n",
    "    INPUT_PROTOCOL = RawProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the NGram itself and its length.\n",
    "    \"\"\"\n",
    "    def mapper(self, ngram, _):\n",
    "        ngram_length = len(ngram)\n",
    "        yield None, (ngram_length, ngram)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the longest ngram from the incoming pairs.\n",
    "    \"\"\"\n",
    "    def combiner(self, _, pairs):\n",
    "        yield None, self.get_longest_ngram(pairs)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the longest ngram from the incoming pairs.\n",
    "    \"\"\"\n",
    "    def reducer(self, _, pairs):\n",
    "        ngram_length, ngram = self.get_longest_ngram(pairs)\n",
    "        yield ngram_length, ngram\n",
    "\n",
    "    \"\"\"\n",
    "    Identify the longest ngram. In the case of ties, it doesn't matter which\n",
    "    one wins, so we'll choose the first one alphabetically.\n",
    "    \"\"\"\n",
    "    def get_longest_ngram(self, pairs):\n",
    "        longest_ngram = None\n",
    "        longest_ngram_length = 0\n",
    "\n",
    "        for ngram_length, ngram in pairs:\n",
    "            if ngram_length > longest_ngram_length:\n",
    "                longest_ngram = ngram\n",
    "                longest_ngram_length = ngram_length\n",
    "            elif ngram_length == longest_ngram_length and ngram < longest_ngram:\n",
    "                longest_ngram = ngram\n",
    "\n",
    "        return longest_ngram_length, longest_ngram\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    LongestNGram().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.3.1 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 486 ms, sys: 59.3 ms, total: 545 ms\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('LongestNGram.py', 'mrjob_531', 'ngrams', 'ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\t\"AIOPJUMRXUYVASLYHYPSIBEMAPODIKR UFRYDIUUOLBIGASUAURUSREXLISNAYE RNOONDQSRUNSUBUNOUGRABBERYAIRTC UTAHRAPTOREDILEIPMILBDUMMYUVERI SYEVRAHVELOCYALLOSAURUSLINROTSR\"\r\n"
     ]
    }
   ],
   "source": [
    "save_job_output('mrjob_531', 'ngrams', 'mrjob_531_output.txt')\n",
    "!sort -k1nr 'mrjob_531_output.txt' | head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do some EDA on this dataset using mrjob: Top 10 most frequent words (please use the count information), i.e., unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing data exploration, we can avoid the single reducer problem as well as the strange Hadoop combiner sort bug by emitting one value per reducer and then doing a simple sort of the output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5.3.2 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import RawProtocol\n",
    "\n",
    "class MostFrequentUnigrams(MRJob):\n",
    "    INPUT_PROTOCOL = RawProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the word counts.\n",
    "    \"\"\"\n",
    "    def mapper(self, doc_id, value):\n",
    "        doc_id = doc_id.lower()\n",
    "\n",
    "        split_value = value.split('\\t')\n",
    "        ngram_count = int(split_value[0])\n",
    "\n",
    "        word_counts = {}\n",
    "\n",
    "        for word in doc_id.split(' '):\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += ngram_count\n",
    "            else:\n",
    "                word_counts[word] = ngram_count\n",
    "\n",
    "        for word, count in word_counts.iteritems():\n",
    "            yield word, count\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed word counts.\n",
    "    \"\"\"\n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed word counts.\n",
    "    \"\"\"\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    MostFrequentUnigrams().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.3.2 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 952 ms, sys: 164 ms, total: 1.12 s\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('MostFrequentUnigrams.py', 'mrjob_532', 'ngrams', 'ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_532', 'ngrams', 'mrjob_532_output.txt')\n",
    "!sort -k2nr -k1 mrjob_532_output.txt > mrjob_532_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t5490815394\r\n",
      "\"of\"\t3698583299\r\n",
      "\"to\"\t2227866570\r\n",
      "\"in\"\t1421312776\r\n",
      "\"a\"\t1361123022\r\n",
      "\"and\"\t1149577477\r\n",
      "\"that\"\t802921147\r\n",
      "\"is\"\t758328796\r\n",
      "\"be\"\t688707130\r\n",
      "\"as\"\t492170314\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 mrjob_532_output_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do some EDA on this dataset using mrjob: 20 Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing data exploration, we can avoid the single reducer problem as well as the strange Hadoop combiner sort bug by emitting one value per reducer and then doing a simple sort of the output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create 5.3.3 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import RawProtocol\n",
    "\n",
    "class MostDenselyAppearingWords(MRJob):\n",
    "    INPUT_PROTOCOL = RawProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the word counts and page counts.\n",
    "    \"\"\"\n",
    "    def mapper(self, doc_id, value):\n",
    "        doc_id = doc_id.lower()\n",
    "\n",
    "        split_value = value.split('\\t')\n",
    "        ngram_count = int(split_value[0])\n",
    "        page_count = int(split_value[1])\n",
    "\n",
    "        word_counts = {}\n",
    "\n",
    "        for word in doc_id.split(' '):\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += ngram_count\n",
    "            else:\n",
    "                word_counts[word] = ngram_count\n",
    "\n",
    "        for word, count in word_counts.iteritems():\n",
    "            yield word, (count, page_count)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed word counts and page counts.\n",
    "    \"\"\"\n",
    "    def combiner(self, word, pairs):\n",
    "        yield word, self.get_pairs_sum(pairs)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed word counts and page counts.\n",
    "    \"\"\"\n",
    "    def reducer(self, word, pairs):\n",
    "        total_word_count, total_page_count = self.get_pairs_sum(pairs)\n",
    "\n",
    "        yield word, float(total_word_count) / float(total_page_count)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed word counts and page counts.\n",
    "    \"\"\"\n",
    "    def get_pairs_sum(self, pairs):\n",
    "        total_word_count = 0\n",
    "        total_page_count = 0\n",
    "\n",
    "        for word_count, page_count in pairs:\n",
    "            total_word_count += word_count\n",
    "            total_page_count += page_count\n",
    "\n",
    "        return (total_word_count, total_page_count)\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    MostDenselyAppearingWords().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.3.3 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 156 ms, total: 1.17 s\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('MostDenselyAppearingWords.py', 'mrjob_533', 'ngrams', 'ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_533', 'ngrams', 'mrjob_533_output.txt')\n",
    "!sort -k1nr -k2 mrjob_533_output.txt > mrjob_533_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.786458333333336\t\"xxxx\"\r\n",
      "37.666666666666664\t\"nnn\"\r\n",
      "30.60614934114202\t\"blah\"\r\n",
      "24.609375\t\"oooooooooooooooo\"\r\n",
      "22.558139534883722\t\"llll\"\r\n",
      "18.963547995139734\t\"oooooo\"\r\n",
      "17.5\t\"xxxxxxxx\"\r\n",
      "16.635396724101255\t\"ooooo\"\r\n",
      "11.290476190476191\t\"choh\"\r\n",
      "10.034392999556934\t\"na\"\r\n",
      "9.965657249196413\t\"nd\"\r\n",
      "9.395604395604396\t\"iooo\"\r\n",
      "8.306397306397306\t\"illl\"\r\n",
      "6.107142857142857\t\"neg\"\r\n",
      "5.357142857142857\t\"oooooooo\"\r\n",
      "4.8193146417445485\t\"iiii\"\r\n",
      "4.216117216117216\t\"vir\"\r\n",
      "4.106772422208664\t\"nn\"\r\n",
      "3.9881422924901186\t\"ome\"\r\n",
      "3.9573934837092732\t\"beep\"\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 mrjob_533_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\t\"zwingst\"\r\n",
      "1.0\t\"zwirnen\"\r\n",
      "1.0\t\"zwischenstaatlicher\"\r\n",
      "1.0\t\"zwitterionic\"\r\n",
      "1.0\t\"zwt\"\r\n",
      "1.0\t\"zwyn\"\r\n",
      "1.0\t\"zx\"\r\n",
      "1.0\t\"zxcvframeqasfuc\"\r\n",
      "1.0\t\"zydeco\"\r\n",
      "1.0\t\"zydom\"\r\n",
      "1.0\t\"zygmunt\"\r\n",
      "1.0\t\"zygomaticofacial\"\r\n",
      "1.0\t\"zygomaticotemporal\"\r\n",
      "1.0\t\"zygosity\"\r\n",
      "1.0\t\"zylindrischen\"\r\n",
      "1.0\t\"zymelman\"\r\n",
      "1.0\t\"zymogens\"\r\n",
      "1.0\t\"zymophore\"\r\n",
      "1.0\t\"zymosan\"\r\n",
      "1.0\t\"zymosis\"\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 mrjob_533_output_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Do some EDA on this dataset using mrjob: Distribution of 5-gram sizes (character length).  E.g., count (using the count field) up how many times a 5-gram of 50 characters shows up. Plot the data graphically using a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5.3.4 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import RawProtocol\n",
    "\n",
    "class NGramLengthCounts(MRJob):\n",
    "    INPUT_PROTOCOL = RawProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the length and the count.\n",
    "    \"\"\"\n",
    "    def mapper(self, ngram, value):\n",
    "        ngram_length = len(ngram)\n",
    "\n",
    "        split_value = value.split('\\t')\n",
    "        ngram_count = int(split_value[0])\n",
    "\n",
    "        yield ngram_length, ngram_count\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed counts.\n",
    "    \"\"\"\n",
    "    def combiner(self, ngram_length, counts):\n",
    "        yield ngram_length, sum(counts)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the summed counts.\n",
    "    \"\"\"\n",
    "    def reducer(self, ngram_length, counts):\n",
    "        yield ngram_length, sum(counts)\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    NGramLengthCounts().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.3.4 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 553 ms, sys: 73.7 ms, total: 627 ms\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('NGramLengthCounts.py', 'mrjob_534', 'ngrams', 'ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_534', 'ngrams', 'mrjob_534_output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot length histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA74AAAGRCAYAAABCG2/LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfdyQAAAAAElFTkSuQmCC\n",
      "text/plain": [
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "length_frequencies = []\n",
    "\n",
    "# Build up the frequencies manually, because there may be gaps in the input\n",
    "# that we need to fill in with zeroes.\n",
    "\n",
    "with open('mrjob_534_output.txt', 'r') as output_file:\n",
    "    for row in csv.reader(output_file, delimiter = '\\t'):\n",
    "        index = int(row[0])\n",
    "\n",
    "        for i in range(len(length_frequencies), index + 1):\n",
    "            length_frequencies.append(0)\n",
    "\n",
    "        length_frequencies[index] = int(row[1])\n",
    "\n",
    "# Create a histogram using matplotlib.\n",
    "\n",
    "bin_count = len(length_frequencies)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(16, 6))\n",
    "matplotlib.pyplot.xlabel(\"length of 5-gram\")\n",
    "matplotlib.pyplot.ylabel(\"frequency\")\n",
    "matplotlib.pyplot.title(\"Histogram of 5-Gram Lengths\")\n",
    "matplotlib.pyplot.hist(range(0, bin_count), bin_count, weights = length_frequencies, color='#797f8b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.3.5 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the log-log plot of the frequency distribution of unigrams. Does it follow power law distribution?\n",
    "\n",
    "> For more background see:\n",
    "\n",
    "> * https://en.wikipedia.org/wiki/Log%E2%80%93log_plot\n",
    "> * https://en.wikipedia.org/wiki/Power_law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAGRCAYAAABPBR+MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNKfuKiMevQAAAABJRU5ErkJggg==\n",
      "text/plain": [
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "unigram_frequencies = []\n",
    "\n",
    "# Build up the frequencies manually, because there may be gaps in the input\n",
    "# that we need to fill in with zeroes.\n",
    "\n",
    "with open('mrjob_532_output.txt', 'r') as output_file:\n",
    "    for row in csv.reader(output_file, delimiter = '\\t'):\n",
    "        log_index = int(math.log(int(row[1])))\n",
    "\n",
    "        for i in range(len(unigram_frequencies), log_index + 1):\n",
    "            unigram_frequencies.append(0)\n",
    "\n",
    "        unigram_frequencies[log_index] += 1\n",
    "\n",
    "log_unigram_frequencies = [math.log(x) if x != 0 else 0 for x in unigram_frequencies]\n",
    "\n",
    "# Create a histogram using matplotlib.\n",
    "\n",
    "bin_count = len(log_unigram_frequencies)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(16, 6))\n",
    "matplotlib.pyplot.xlabel('log(term frequency)')\n",
    "matplotlib.pyplot.ylabel('log(frequency)')\n",
    "matplotlib.pyplot.title('Log-Log Plot of Histogram of Term Frequency')\n",
    "matplotlib.pyplot.hist(range(0, bin_count), bin_count, weights = log_unigram_frequencies, color='#797f8b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the [graphical methods for identification](https://en.wikipedia.org/wiki/Power_law#Graphical_methods_for_identification) section of the linked Wikipedia article, since the log-log plot is very close to a straight downward-sloped line, this is strong evidence that the original values follow a power law distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For the remainder of this assignment you will work with two datasets:\n",
    "\n",
    "> (1) unit/systems test data set: SYSTEMS TEST DATASET\n",
    "\n",
    "> Three terms, A,B,C and their corresponding strip-docs of co-occurring terms\n",
    "\n",
    ">```\n",
    "    DocA {X:20, Y:30, Z:5}\n",
    "    DocB {X:100, Y:20}\n",
    "    DocC {M:5, N:20, Z:5}\n",
    "```\n",
    "\n",
    "> (2) A large subset of the Google n-grams dataset as was described above\n",
    "\n",
    "> In this part of the assignment we will focus on developing methods\n",
    "for detecting synonyms, using the Google 5-grams dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unit test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing unit/test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile unit/test.txt\n",
    "DocA\t{'X':20, 'Y':30, 'Z':5}\n",
    "DocB\t{'X':100, 'Y':20}\n",
    "DocC\t{'M':5, 'N':20, 'Z':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal unit $hdfs_base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1) Build stripes for the most frequent 10,000 words using cooccurence information based on\n",
    "the words ranked from 1001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous).\n",
    "\n",
    "> **Design Notes**\n",
    "\n",
    "> For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts\n",
    "across the 5-grams, output the support from the mappers using the total\n",
    "order inversion pattern:\n",
    "\n",
    "> ```\n",
    "    <*word,count>\n",
    "```\n",
    "\n",
    "> to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "> In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already generated the dictionary as part of our exploratory data analysis. Extract the dictionary here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -10000 mrjob_532_output_sorted.txt > ngrams_vocabulary.txt\n",
    "!head -10000 mrjob_532_output_sorted.txt | tail -1000 > ngrams_basis.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5.4.1 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import RawProtocol\n",
    "\n",
    "class StripedNGrams(MRJob):\n",
    "    INPUT_PROTOCOL = RawProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Load the valid dictionary terms.\n",
    "    \"\"\"\n",
    "    def mapper_init(self):\n",
    "        self.basis = set()\n",
    "        self.vocabulary = set()\n",
    "\n",
    "        with open('ngrams_basis.txt', 'r') as basis_file:\n",
    "            self.basis = set([row[0] for row in csv.reader(basis_file, delimiter = '\\t')])\n",
    "\n",
    "        with open('ngrams_vocabulary.txt', 'r') as vocabulary_file:\n",
    "            self.vocabulary = set([row[0] for row in csv.reader(vocabulary_file, delimiter = '\\t')])\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the per-document stripes.\n",
    "    \"\"\"\n",
    "    def mapper(self, ngram, value):\n",
    "        ngram = ngram.lower()\n",
    "\n",
    "        # Parse the word counts separately based on whether we are checking the\n",
    "        # unit test data or the actual ngrams data.\n",
    "\n",
    "        if value[0] == '{':\n",
    "            word_counts = eval(value)\n",
    "            self.basis.update(word_counts.keys())\n",
    "        else:\n",
    "            split_value = value.split('\\t')\n",
    "            ngram_count = int(split_value[0])\n",
    "\n",
    "            word_counts = {}\n",
    "\n",
    "            for word in ngram.split(' '):\n",
    "                if word not in self.vocabulary:\n",
    "                    continue\n",
    "\n",
    "                if word in word_counts:\n",
    "                    word_counts[word] += ngram_count\n",
    "                else:\n",
    "                    word_counts[word] = ngram_count\n",
    "\n",
    "        # Emit all the stripes derived from the word count. Only include keys\n",
    "        # in the stripe if the key is in the basis.\n",
    "\n",
    "        if len(word_counts) < 2:\n",
    "            return\n",
    "\n",
    "        for word, count in word_counts.iteritems():\n",
    "            stripe = {\n",
    "                key: value for key, value in word_counts.iteritems()\n",
    "                    if key != word and key in self.basis\n",
    "            }\n",
    "\n",
    "            if len(stripe) == 0:\n",
    "                continue\n",
    "\n",
    "            stripe['*'] = count\n",
    "\n",
    "            yield word, stripe\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the stripes.\n",
    "    \"\"\"\n",
    "    def combiner(self, word, stripes):\n",
    "        yield word, self.combine_stripes(stripes)\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the stripes and then emit the coccurrence rate.\n",
    "    \"\"\"\n",
    "    def reducer(self, word, stripes):\n",
    "        combined_stripe = self.combine_stripes(stripes)\n",
    "        total_count = combined_stripe['*']\n",
    "\n",
    "        rate_stripe = {\n",
    "            key: float(value) / total_count\n",
    "                for key, value in combined_stripe.iteritems() if key != '*'\n",
    "        }\n",
    "\n",
    "        yield word, rate_stripe\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the stripes.\n",
    "    \"\"\"\n",
    "    def combine_stripes(self, stripes):\n",
    "        combined_stripe = {}\n",
    "\n",
    "        for stripe in stripes:\n",
    "            for key, value in stripe.iteritems():\n",
    "                if key in combined_stripe:\n",
    "                    combined_stripe[key] += value\n",
    "                else:\n",
    "                    combined_stripe[key] = value\n",
    "\n",
    "        return combined_stripe\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    StripedNGrams().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.4.1 unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please unit test and system test your code with with SYSTEMS TEST DATASET and show the results. Please compute the expected answer by hand and show your hand calculations. Then show the results you get with your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have the following data set for the data set:\n",
    "\n",
    "    DocA\t{X:20, Y:30, Z:5}\n",
    "    DocB\t{X:100, Y:20}\n",
    "    DocC\t{M:5, N:20, Z:5}\n",
    "\n",
    "This yields the following per-document stripes, sorted by word:\n",
    "\n",
    "    M\t{*:5, N:20, Z:5}\n",
    "    N\t{*:20, M:5, Z:5}\n",
    "    X\t{*:20, Y:30, Z:5}\n",
    "    X\t{*:100, Y:20}\n",
    "    Y\t{*:30, X:20, Z:5}\n",
    "    Y\t{*:20, X:100}\n",
    "    Z\t{*:5, X:20, Y:30}\n",
    "    Z\t{*:5, M:5, N:20}\n",
    "\n",
    "If we sum them, this yields the following stripes:\n",
    "\n",
    "    M\t{*:5, N:20, Z:5}\n",
    "    N\t{*:20, M:5, Z:5}\n",
    "    X\t{*:120, Y:50, Z:5}\n",
    "    Y\t{*:50, X:120, Z:5}\n",
    "    Z\t{*:10, M:5, N:20, X:20, Y:30}\n",
    "\n",
    "This results in the following final cooccurences:\n",
    "\n",
    "    M\t{N:20/5, Z:5/5}\n",
    "    N\t{M:5/20, Z:5/20}\n",
    "    X\t{Y:50/120, Z:5/120}\n",
    "    Y\t{X:120/50, Z:5/50}\n",
    "    Z\t{M:5/10, N:20/10, X:20/10, Y:30/10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 157 ms, sys: 26.1 ms, total: 183 ms\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%time run_job(\n",
    "    'StripedNGrams.py --file ngrams_basis.txt --file ngrams_vocabulary.txt',\n",
    "    'mrjob_541', 'unit', 'unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"M\"\t{\"Z\": 1.0, \"N\": 4.0}\r\n",
      "\"N\"\t{\"Z\": 0.25, \"M\": 0.25}\r\n",
      "\"X\"\t{\"Y\": 0.4166666666666667, \"Z\": 0.041666666666666664}\r\n",
      "\"Y\"\t{\"X\": 2.4, \"Z\": 0.1}\r\n",
      "\"Z\"\t{\"Y\": 3.0, \"X\": 2.0, \"M\": 0.5, \"N\": 2.0}\r\n"
     ]
    }
   ],
   "source": [
    "save_job_output('mrjob_541', 'unit', 'mrjob_541_unit_output.txt')\n",
    "!cat 'mrjob_541_unit_output.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.4.1 ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally show your results on the Google n-grams dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 666 ms, sys: 60.2 ms, total: 726 ms\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%time run_job(\n",
    "    'StripedNGrams.py --file ngrams_basis.txt --file ngrams_vocabulary.txt',\n",
    "    'mrjob_541', 'ngrams', 'ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9994 mrjob_541_ngrams_output.txt\r\n"
     ]
    }
   ],
   "source": [
    "save_job_output('mrjob_541', 'ngrams', 'mrjob_541_ngrams_output.txt')\n",
    "!wc -l mrjob_541_ngrams_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this part of the assignment we will focus on developing methods\n",
    "for detecting synonyms, using the Google 5-grams dataset.\n",
    "\n",
    "> (2) Using two (symmetric) comparison methods of your choice\n",
    "(e.g., correlations, distances, similarities), pairwise compare\n",
    "all stripes (vectors), and output to a file in your bucket on s3.\n",
    "\n",
    "> **Design Notes**\n",
    "\n",
    "> For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "> * Jaccard\n",
    "> * Cosine similarity\n",
    "> * Spearman correlation\n",
    "> * Euclidean distance\n",
    "> * Taxicab (Manhattan) distance\n",
    "> * Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "> * Pearson correlation\n",
    "> * Kendall correlation\n",
    "\n",
    "> However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary,\n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "> Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create matrix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir('matrix'):\n",
    "    # Unit test file is small so it can appear in one file\n",
    "\n",
    "    !mkdir -p matrix/unit\n",
    "    !cp mrjob_541_unit_output.txt matrix/unit\n",
    "\n",
    "    # NGrams file is large so split it across files that are 100 lines each.\n",
    "\n",
    "    !mkdir -p matrix/ngrams\n",
    "    !split -l 100 --additional-suffix=.txt mrjob_541_ngrams_output.txt matrix/ngrams/mrjob_541_ngrams_output_\n",
    "\n",
    "    # Copy the folders we created to HDFS.\n",
    "\n",
    "    !hdfs dfs -copyFromLocal matrix $hdfs_base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5.4.2 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import functools\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import JSONProtocol\n",
    "\n",
    "class SynonymDetection(MRJob):\n",
    "    INPUT_PROTOCOL = JSONProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Allow distance type to be passed through as a configuration option.\n",
    "    \"\"\"\n",
    "    def configure_options(self):\n",
    "        super(SynonymDetection, self).configure_options()\n",
    "        self.add_passthrough_option('--distance-type', type = 'string', default = 'euclidean')\n",
    "\n",
    "    \"\"\"\n",
    "    Normalize and transpose the matrix.\n",
    "    \"\"\"\n",
    "    def mapper_normalize_transpose(self, word, rate_stripe):\n",
    "\n",
    "        # First compute the magnitude for the vector.\n",
    "\n",
    "        magnitude = math.sqrt(sum([value ** 2 for value in rate_stripe.itervalues()]))\n",
    "\n",
    "        # Divide each value in the vector by the magnitude to normalize.\n",
    "\n",
    "        for key, value in rate_stripe.iteritems():\n",
    "            normalized_value = value / magnitude\n",
    "            yield key, { word: normalized_value }\n",
    "\n",
    "    \"\"\"\n",
    "    Combine the stripes.\n",
    "    \"\"\"\n",
    "    def combiner_normalize_transpose(self, word, transpose_stripes):\n",
    "        yield word, self.combine_stripes(transpose_stripes)\n",
    "\n",
    "    \"\"\"\n",
    "    Combine the stripes.\n",
    "    \"\"\"\n",
    "    def reducer_normalize_transpose(self, word, transpose_stripes):\n",
    "        yield word, self.combine_stripes(transpose_stripes)\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the cosine distance based on the normalized vectors.\n",
    "    \"\"\"\n",
    "    def mapper_cosine(self, word, transpose_stripe):\n",
    "\n",
    "        # Sort the key-value pairs to ensure we are consistent about what\n",
    "        # we emit in our symmetric matrix.\n",
    "\n",
    "        sorted_pairs = sorted(transpose_stripe.iteritems())\n",
    "\n",
    "        for i in range(0, len(sorted_pairs)):\n",
    "            left_label, left_value = sorted_pairs[i]\n",
    "\n",
    "            stripe = {}\n",
    "\n",
    "            for j in range(i + 1, len(sorted_pairs)):\n",
    "                right_label, right_value = sorted_pairs[j]\n",
    "                partial_distance = left_value * right_value\n",
    "\n",
    "                if partial_distance > 0:\n",
    "                    stripe[right_label] = partial_distance\n",
    "\n",
    "            yield left_label, stripe\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the partial distances based on the data contained in the stripe.\n",
    "    \"\"\"\n",
    "    def combiner_cosine(self, left_label, partial_stripes):\n",
    "        yield left_label, self.combine_stripes(partial_stripes)\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the partial distances and take the logarithm for sorting.\n",
    "    \"\"\"\n",
    "    def reducer_cosine(self, left_label, partial_stripes):\n",
    "        total_stripe = self.combine_stripes(partial_stripes)\n",
    "\n",
    "        for right_label, sum_distance in total_stripe.iteritems():\n",
    "            coordinate = (left_label, right_label)\n",
    "            yield coordinate, math.log(sum_distance)\n",
    "\n",
    "    \"\"\"\n",
    "    Emit all the pairs as stripes.\n",
    "    \"\"\"\n",
    "    def mapper_jaccard(self, word, rate_stripe):\n",
    "        nonzero_keys = [key for key, value in rate_stripe.iteritems() if value != 0]\n",
    "\n",
    "        # Emit a stripe for each combination of values that we see\n",
    "        # in the stripe.\n",
    "\n",
    "        sorted_keys = sorted(nonzero_keys)\n",
    "\n",
    "        for i in range(0, len(sorted_keys)):\n",
    "            left_label = sorted_keys[i]\n",
    "\n",
    "            stripe = {}\n",
    "\n",
    "            for j in range(i + 1, len(sorted_keys)):\n",
    "                right_label = sorted_keys[j]\n",
    "                stripe[right_label] = 1\n",
    "\n",
    "            yield left_label, stripe\n",
    "\n",
    "        # Emit another stripe to use to tally the total counts. We will\n",
    "        # use '*' so that it is the first value we see in the reducer.\n",
    "\n",
    "        yield '*', { key: 1 for key in sorted_keys }\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the partial distances based on the data contained in the stripe.\n",
    "    \"\"\"\n",
    "    def combiner_jaccard(self, left_label, partial_stripes):\n",
    "        yield left_label, self.combine_stripes(partial_stripes)\n",
    "\n",
    "    \"\"\"\n",
    "    Reducer which aggregates the stripes and then divides by the counts\n",
    "    that are returned by the '*' stripe. Take the logarithm for sorting.\n",
    "    \"\"\"\n",
    "    def reducer_jaccard(self, left_label, partial_stripes):\n",
    "        total_stripe = self.combine_stripes(partial_stripes)\n",
    "\n",
    "        if left_label == '*':\n",
    "            self.total_counts = total_stripe\n",
    "            return\n",
    "\n",
    "        for right_label, intersection_size in total_stripe.iteritems():\n",
    "            coordinate = (left_label, right_label)\n",
    "            union_size = self.total_counts[left_label] + self.total_counts[right_label]\n",
    "\n",
    "            # Subtract the logarithms instead of taking the logarithm of\n",
    "            # the quotient to avoid potential underflow.\n",
    "\n",
    "            jaccard_distance = math.log(intersection_size) - math.log(union_size - intersection_size)\n",
    "\n",
    "            yield coordinate, jaccard_distance\n",
    "\n",
    "    \"\"\"\n",
    "    Sum the stripes.\n",
    "    \"\"\"\n",
    "    def combine_stripes(self, stripes):\n",
    "        combined_stripe = {}\n",
    "\n",
    "        for stripe in stripes:\n",
    "            for key, value in stripe.iteritems():\n",
    "                if key in combined_stripe:\n",
    "                    combined_stripe[key] += value\n",
    "                else:\n",
    "                    combined_stripe[key] = value\n",
    "\n",
    "        return combined_stripe\n",
    "\n",
    "    \"\"\"\n",
    "    Define multi-step reducer.\n",
    "    \"\"\"\n",
    "    def steps(self):\n",
    "\n",
    "        transpose_step = MRStep(\n",
    "            mapper = self.mapper_normalize_transpose,\n",
    "            combiner = self.combiner_normalize_transpose,\n",
    "            reducer = self.reducer_normalize_transpose)\n",
    "\n",
    "        # For cosine, we need to first take the transpose in order to create\n",
    "        # the inverted index. Then compute the cosine.\n",
    "\n",
    "        if self.options.distance_type == 'cosine':\n",
    "            distance_step = MRStep(\n",
    "                mapper = self.mapper_cosine,\n",
    "                combiner = self.combiner_cosine,\n",
    "                reducer = self.reducer_cosine)\n",
    "\n",
    "        # For Jaccard, we first take the transpose in order to create the\n",
    "        # inverted index. Since we need the total counts of each set in\n",
    "        # order to compute the score, we limit it to one reducer.\n",
    "\n",
    "        else:\n",
    "            distance_step = MRStep(\n",
    "                mapper = self.mapper_jaccard,\n",
    "                combiner = self.combiner_jaccard,\n",
    "                reducer = self.reducer_jaccard,\n",
    "                jobconf = {\n",
    "                    'mapreduce.job.reduces': 1\n",
    "                })\n",
    "\n",
    "        return [transpose_step, distance_step]\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    SynonymDetection().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.4.2 unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please unit test and system test your code with with SYSTEMS TEST DATASET and show the results. Please compute the expected answer by hand and show your hand calculations. Then show the results you get with your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 unit log-jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the following cooccurrences:\n",
    "\n",
    "    M\t{N:20/5, Z:5/5}\n",
    "    N\t{M:5/20, Z:5/20}\n",
    "    X\t{Y:50/120, Z:5/120}\n",
    "    Y\t{X:120/50, Z:5/50}\n",
    "    Z\t{M:5/10, N:20/10, X:20/10, Y:30/10}\n",
    "\n",
    "We can binarize it as follows:\n",
    "\n",
    "    M\t{N, Z}\n",
    "    N\t{M, Z}\n",
    "    X\t{Y, Z}\n",
    "    Y\t{X, Z}\n",
    "    Z\t{M, N, X, Y}\n",
    "\n",
    "Therefore, we can compute the Jaccard index based on the interaction and the union of the two sets:\n",
    "\n",
    "    M,N = 1/3\n",
    "    M,X = 1/3\n",
    "    M,Y = 1/3\n",
    "    M,Z = 1/5\n",
    "    N,X = 1/3\n",
    "    N,Y = 1/3\n",
    "    N,Z = 1/5\n",
    "    X,Y = 1/3\n",
    "    X,Z = 1/5\n",
    "    Y,Z = 1/5\n",
    "\n",
    "If we then take the logarithm, we would expect the following result:\n",
    "\n",
    "    M,N = -1.0986122886681098\n",
    "    M,X = -1.0986122886681098\n",
    "    M,Y = -1.0986122886681098\n",
    "    M,Z = -1.6094379124341003\n",
    "    N,X = -1.0986122886681098\n",
    "    N,Y = -1.0986122886681098\n",
    "    N,Z = -1.6094379124341003\n",
    "    X,Y = -1.0986122886681098\n",
    "    X,Z = -1.6094379124341003\n",
    "    Y,Z = -1.6094379124341003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 50.6 ms, total: 243 ms\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('SynonymDetection.py --distance-type=jaccard', 'mrjob_542', 'unit_jaccard', 'matrix/unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_542', 'unit_jaccard', 'mrjob_542_unit_jaccard_output.txt')\n",
    "!sort -k1 -k2 mrjob_542_unit_jaccard_output.txt > mrjob_542_unit_jaccard_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"M\", \"N\"]\t-1.0986122886681098\r\n",
      "[\"M\", \"X\"]\t-1.0986122886681098\r\n",
      "[\"M\", \"Y\"]\t-1.0986122886681098\r\n",
      "[\"M\", \"Z\"]\t-1.6094379124341003\r\n",
      "[\"N\", \"X\"]\t-1.0986122886681098\r\n",
      "[\"N\", \"Y\"]\t-1.0986122886681098\r\n",
      "[\"N\", \"Z\"]\t-1.6094379124341003\r\n",
      "[\"X\", \"Y\"]\t-1.0986122886681098\r\n",
      "[\"X\", \"Z\"]\t-1.6094379124341003\r\n",
      "[\"Y\", \"Z\"]\t-1.6094379124341003\r\n"
     ]
    }
   ],
   "source": [
    "!cat mrjob_542_unit_jaccard_output_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 unit log-cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the following co-occurrences:\n",
    "\n",
    "    M\t{N:20/5, Z:5/5}\n",
    "    N\t{M:5/20, Z:5/20}\n",
    "    X\t{Y:50/120, Z:5/120}\n",
    "    Y\t{X:120/50, Z:5/50}\n",
    "    Z\t{M:5/10, N:20/10, X:20/10, Y:30/10}\n",
    "\n",
    "If we normalize each of these vectors, we get the following:\n",
    "\n",
    "    M\t{N: 0.9701425001453319, Z: 0.24253562503633297}\n",
    "    N\t{M: 0.7071067811865475, Z: 0.7071067811865475}\n",
    "    X\t{Y: 0.9950371902099892, Z: 0.0995037190209989}\n",
    "    Y\t{X: 0.9991330730923519, Z: 0.04163054471218133}\n",
    "    Z\t{M: 0.1203858530857692, N: 0.4815434123430768, Y: 0.7223151185146152, X: 0.4815434123430768}\n",
    "\n",
    "If we manually compute the cosine using these normalized vectors, we get the following:\n",
    "\n",
    "    M,N = 0.17149858514250882\n",
    "    M,X = 0.024133196686197622\n",
    "    M,Y = 0.010096890182371906\n",
    "    M,Z = 0.467165729979027\n",
    "    N,X = 0.07035975447302917\n",
    "    N,Y = 0.029437240470473188\n",
    "    N,Z = 0.08512565307587484\n",
    "    X,Y = 0.004142394023732023\n",
    "    X,Z = 0.718730405972978\n",
    "    Y,Z = 0.4811259494017159\n",
    "\n",
    "If we take the logarithm of these cosine values to make it easier to sort in MapReduce (in the event that it starts emitting values in scientific notation), we get the following:\n",
    "\n",
    "    M,N = -1.7631802623080808\n",
    "    M,X = -3.724166930448738\n",
    "    M,Y = -4.595527805282158\n",
    "    M,Z = -0.7610712020869566\n",
    "    N,X = -2.6541338487006025\n",
    "    N,Y = -3.5254947235340226\n",
    "    N,Z = -2.4636268425786025\n",
    "    X,Y = -5.48648139167468\n",
    "    X,Z = -0.33026894849715877\n",
    "    Y,Z = -0.7316261940848433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 ms, sys: 47 ms, total: 265 ms\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('SynonymDetection.py --distance-type=cosine', 'mrjob_542', 'unit_cosine', 'matrix/unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_542', 'unit_cosine', 'mrjob_542_unit_cosine_output.txt')\n",
    "!sort -k1 -k2 mrjob_542_unit_cosine_output.txt > mrjob_542_unit_cosine_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"M\", \"N\"]\t-1.7631802623080808\r\n",
      "[\"M\", \"X\"]\t-3.724166930448738\r\n",
      "[\"M\", \"Y\"]\t-4.595527805282158\r\n",
      "[\"M\", \"Z\"]\t-0.7610712020869566\r\n",
      "[\"N\", \"X\"]\t-2.6541338487006025\r\n",
      "[\"N\", \"Y\"]\t-3.5254947235340226\r\n",
      "[\"N\", \"Z\"]\t-2.4636268425786025\r\n",
      "[\"X\", \"Y\"]\t-5.48648139167468\r\n",
      "[\"X\", \"Z\"]\t-0.33026894849715877\r\n",
      "[\"Y\", \"Z\"]\t-0.7316261940848433\r\n"
     ]
    }
   ],
   "source": [
    "!cat mrjob_542_unit_cosine_output_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5.4.2 ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally show your results on the Google n-grams dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 ngrams log-jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 175 ms, sys: 50.4 ms, total: 225 ms\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('SynonymDetection.py --distance-type=jaccard', 'mrjob_542', 'ngrams_jaccard', 'matrix/ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_542', 'ngrams_jaccard', 'mrjob_542_ngrams_jaccard_output.txt')\n",
    "!sort -k3nr mrjob_542_ngrams_jaccard_output.txt > mrjob_542_ngrams_jaccard_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"clues\", \"resolving\"]\t-0.916290731874155\r\n",
      "[\"hydroxide\", \"sulphate\"]\t-0.9555114450274365\r\n",
      "[\"ammonium\", \"sulphate\"]\t-1.0414538748281612\r\n",
      "[\"esophagus\", \"mitral\"]\t-1.0986122886681098\r\n",
      "[\"gaza\", \"nationalist\"]\t-1.0986122886681098\r\n",
      "[\"avert\", \"incur\"]\t-1.1349799328389842\r\n",
      "[\"ammonium\", \"filtered\"]\t-1.1526795099383853\r\n",
      "[\"est\", \"qui\"]\t-1.1526795099383853\r\n",
      "[\"ammonium\", \"hydroxide\"]\t-1.1631508098056809\r\n",
      "[\"filtered\", \"sulphate\"]\t-1.2237754316221159\r\n",
      "[\"articular\", \"cartilage\"]\t-1.252762968495368\r\n",
      "[\"articulation\", \"experimentally\"]\t-1.252762968495368\r\n",
      "[\"sabha\", \"singapore\"]\t-1.252762968495368\r\n",
      "[\"ce\", \"est\"]\t-1.2809338454620642\r\n",
      "[\"acetic\", \"hydroxide\"]\t-1.2992829841302609\r\n",
      "[\"amazement\", \"diversion\"]\t-1.2992829841302609\r\n",
      "[\"farthest\", \"remotest\"]\t-1.2992829841302609\r\n",
      "[\"miseries\", \"misfortunes\"]\t-1.3268709406490897\r\n",
      "[\"prosecuted\", \"sued\"]\t-1.33500106673234\r\n",
      "[\"approximated\", \"entropy\"]\t-1.3862943611198904\r\n",
      "[\"approximated\", \"logarithm\"]\t-1.3862943611198904\r\n",
      "[\"backbone\", \"gaza\"]\t-1.3862943611198906\r\n",
      "[\"backbone\", \"nationalist\"]\t-1.3862943611198906\r\n",
      "[\"backbone\", \"randomly\"]\t-1.3862943611198906\r\n",
      "[\"filtered\", \"hydroxide\"]\t-1.3862943611198906\r\n",
      "[\"foreground\", \"transitional\"]\t-1.3862943611198906\r\n",
      "[\"osmotic\", \"randomly\"]\t-1.3862943611198906\r\n",
      "[\"ammonium\", \"insoluble\"]\t-1.4271163556401456\r\n",
      "[\"abyss\", \"insensible\"]\t-1.4350845252893227\r\n",
      "[\"alzheimer's\", \"screening\"]\t-1.4469189829363256\r\n",
      "[\"ovary\", \"placenta\"]\t-1.4469189829363256\r\n",
      "[\"ovary\", \"plexus\"]\t-1.4469189829363256\r\n",
      "[\"peritoneal\", \"placenta\"]\t-1.4469189829363256\r\n",
      "[\"acetic\", \"sulphate\"]\t-1.466337068793427\r\n",
      "[\"cornea\", \"pancreas\"]\t-1.4816045409242158\r\n",
      "[\"alzheimer's\", \"correlate\"]\t-1.504077396776274\r\n",
      "[\"ce\", \"qui\"]\t-1.504077396776274\r\n",
      "[\"abnormalities\", \"morphology\"]\t-1.5040773967762742\r\n",
      "[\"dysfunction\", \"skeletal\"]\t-1.5040773967762742\r\n",
      "[\"lutheran\", \"psychoanalytic\"]\t-1.5040773967762742\r\n",
      "[\"abnormalities\", \"atrophy\"]\t-1.5314763709643886\r\n",
      "[\"complexion\", \"hue\"]\t-1.5314763709643886\r\n",
      "[\"dryness\", \"sulphate\"]\t-1.5404450409471486\r\n",
      "[\"alzheimer's\", \"dementia\"]\t-1.5581446180465497\r\n",
      "[\"ills\", \"vicissitudes\"]\t-1.5581446180465497\r\n",
      "[\"pancreas\", \"placenta\"]\t-1.5581446180465497\r\n",
      "[\"phosphorus\", \"precursor\"]\t-1.5581446180465497\r\n",
      "[\"phosphorus\", \"sulphate\"]\t-1.5581446180465497\r\n",
      "[\"alveolar\", \"skeletal\"]\t-1.5804503755608483\r\n",
      "[\"accrue\", \"fide\"]\t-1.6094379124341003\r\n",
      "[\"acetic\", \"filtered\"]\t-1.6094379124341003\r\n",
      "[\"alveolar\", \"maxillary\"]\t-1.6094379124341003\r\n",
      "[\"annum\", \"purchases\"]\t-1.6094379124341003\r\n",
      "[\"articulation\", \"disruption\"]\t-1.6094379124341003\r\n",
      "[\"backbone\", \"osmotic\"]\t-1.6094379124341003\r\n",
      "[\"chord\", \"incubation\"]\t-1.6094379124341003\r\n",
      "[\"classify\", \"revert\"]\t-1.6094379124341003\r\n",
      "[\"classify\", \"unfamiliar\"]\t-1.6094379124341003\r\n",
      "[\"concede\", \"deduce\"]\t-1.6094379124341003\r\n",
      "[\"confuse\", \"dictate\"]\t-1.6094379124341003\r\n",
      "[\"confuse\", \"formative\"]\t-1.6094379124341003\r\n",
      "[\"correlate\", \"schizophrenia\"]\t-1.6094379124341003\r\n",
      "[\"dietary\", \"uptake\"]\t-1.6094379124341003\r\n",
      "[\"environments\", \"impacts\"]\t-1.6094379124341003\r\n",
      "[\"filtered\", \"soda\"]\t-1.6094379124341003\r\n",
      "[\"ieee\", \"undergraduate\"]\t-1.6094379124341003\r\n",
      "[\"kashmir\", \"sabha\"]\t-1.6094379124341003\r\n",
      "[\"nationals\", \"restrictive\"]\t-1.6094379124341003\r\n",
      "[\"ovary\", \"uterine\"]\t-1.6094379124341003\r\n",
      "[\"palestinian\", \"unprecedented\"]\t-1.6094379124341003\r\n",
      "[\"skeletal\", \"uterine\"]\t-1.6094379124341003\r\n",
      "[\"accrue\", \"dividend\"]\t-1.6094379124341005\r\n",
      "[\"accumulate\", \"maxillary\"]\t-1.6094379124341005\r\n",
      "[\"cons\", \"iran\"]\t-1.6094379124341005\r\n",
      "[\"demonstrating\", \"inferences\"]\t-1.6094379124341005\r\n",
      "[\"electorate\", \"individually\"]\t-1.6094379124341005\r\n",
      "[\"entropy\", \"logarithm\"]\t-1.6094379124341005\r\n",
      "[\"entropy\", \"unrelated\"]\t-1.6094379124341005\r\n",
      "[\"halfway\", \"lobby\"]\t-1.6094379124341005\r\n",
      "[\"monitored\", \"operative\"]\t-1.6094379124341005\r\n",
      "[\"predicting\", \"rating\"]\t-1.6094379124341005\r\n",
      "[\"singapore\", \"sri\"]\t-1.6094379124341005\r\n",
      "[\"arthritis\", \"transplantation\"]\t-1.6486586255873819\r\n",
      "[\"cartilage\", \"necrosis\"]\t-1.6486586255873819\r\n",
      "[\"au\", \"qui\"]\t-1.6582280766035324\r\n",
      "[\"dryness\", \"insoluble\"]\t-1.6582280766035324\r\n",
      "[\"lymphocytes\", \"placenta\"]\t-1.6582280766035324\r\n",
      "[\"shoe\", \"steamer\"]\t-1.6582280766035324\r\n",
      "[\"acetic\", \"ammonium\"]\t-1.6739764335716714\r\n",
      "[\"commonest\", \"congestive\"]\t-1.6739764335716714\r\n",
      "[\"complexion\", \"flush\"]\t-1.6863989535702288\r\n",
      "[\"abnormalities\", \"rabbit\"]\t-1.7047480922384253\r\n",
      "[\"advertisement\", \"intrusted\"]\t-1.7047480922384253\r\n",
      "[\"americas\", \"nova\"]\t-1.7047480922384253\r\n",
      "[\"arkansas\", \"tourism\"]\t-1.7047480922384253\r\n",
      "[\"bombing\", \"brunt\"]\t-1.7047480922384253\r\n",
      "[\"bucket\", \"halfway\"]\t-1.7047480922384253\r\n",
      "[\"bucket\", \"lobby\"]\t-1.7047480922384253\r\n",
      "[\"bucket\", \"upstairs\"]\t-1.7047480922384253\r\n",
      "[\"contributors\", \"painters\"]\t-1.7047480922384253\r\n"
     ]
    }
   ],
   "source": [
    "!head -100 mrjob_542_ngrams_jaccard_output_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 ngrams log-cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 31.4 ms, total: 252 ms\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%time run_job('SynonymDetection.py --distance-type=cosine', 'mrjob_542', 'ngrams_cosine', 'matrix/ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_job_output('mrjob_542', 'ngrams_cosine', 'mrjob_542_ngrams_cosine_output.txt')\n",
    "!sort -k3nr mrjob_542_ngrams_cosine_output.txt > mrjob_542_ngrams_cosine_output_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"remission\", \"sinners\"]\t-0.0032786960928299263\r\n",
      "[\"bacon\", \"cheese\"]\t-0.02775930743649666\r\n",
      "[\"glasgow\", \"lutheran\"]\t-0.03296908447869242\r\n",
      "[\"backbone\", \"randomly\"]\t-0.03503814691209745\r\n",
      "[\"excesses\", \"parked\"]\t-0.03856764883299232\r\n",
      "[\"hundredth\", \"zenith\"]\t-0.03939167143715864\r\n",
      "[\"adviser\", \"disclosure\"]\t-0.04250176481101884\r\n",
      "[\"repaid\", \"testified\"]\t-0.04827938434133423\r\n",
      "[\"officially\", \"rs\"]\t-0.05950863190029749\r\n",
      "[\"humiliation\", \"nuisance\"]\t-0.07533933711020277\r\n",
      "[\"complexion\", \"hue\"]\t-0.08333875146566773\r\n",
      "[\"fossil\", \"spherical\"]\t-0.08375319124259495\r\n",
      "[\"discomfort\", \"nuisance\"]\t-0.08703976109333353\r\n",
      "[\"hay\", \"neat\"]\t-0.09315707176381062\r\n",
      "[\"flourishing\", \"plentiful\"]\t-0.09387858817533977\r\n",
      "[\"weep\", \"wept\"]\t-0.10078934123510001\r\n",
      "[\"fibrous\", \"flexor\"]\t-0.10759708291419438\r\n",
      "[\"hydroxide\", \"purified\"]\t-0.11180066983853443\r\n",
      "[\"flush\", \"roses\"]\t-0.11324335375998704\r\n",
      "[\"funded\", \"individually\"]\t-0.11381486062555761\r\n",
      "[\"crowns\", \"danube\"]\t-0.11556477825388847\r\n",
      "[\"contending\", \"rivalry\"]\t-0.12375334942311102\r\n",
      "[\"futility\", \"matthew\"]\t-0.12939141122971803\r\n",
      "[\"trembled\", \"unprecedented\"]\t-0.13668330267816906\r\n",
      "[\"crosses\", \"uterine\"]\t-0.13775312145537358\r\n",
      "[\"amplifier\", \"cathode\"]\t-0.1386177270116658\r\n",
      "[\"discomfort\", \"humiliation\"]\t-0.14081281266531695\r\n",
      "[\"feathers\", \"serpent\"]\t-0.14365884035518048\r\n",
      "[\"anarchy\", \"realizes\"]\t-0.144411074945735\r\n",
      "[\"explanatory\", \"favorably\"]\t-0.14695207942287505\r\n",
      "[\"annum\", \"trademarks\"]\t-0.14872023166408474\r\n",
      "[\"survivor\", \"uniqueness\"]\t-0.14903226640527367\r\n",
      "[\"printer\", \"probe\"]\t-0.15001271077948908\r\n",
      "[\"terminology\", \"usages\"]\t-0.15610614842568385\r\n",
      "[\"au\", \"est\"]\t-0.15789654226412542\r\n",
      "[\"polarization\", \"probe\"]\t-0.16318020735965927\r\n",
      "[\"acetic\", \"ether\"]\t-0.16764959759253026\r\n",
      "[\"illuminated\", \"probe\"]\t-0.16910179549404578\r\n",
      "[\"nuisance\", \"sack\"]\t-0.17047736427189583\r\n",
      "[\"alzheimer's\", \"screening\"]\t-0.1721996502658673\r\n",
      "[\"boxes\", \"hay\"]\t-0.17244062877473876\r\n",
      "[\"jones\", \"linguistics\"]\t-0.17527410118392334\r\n",
      "[\"boxes\", \"neat\"]\t-0.18507180453697175\r\n",
      "[\"grandson\", \"versailles\"]\t-0.1910510188452996\r\n",
      "[\"displeasure\", \"indebtedness\"]\t-0.19323670730067394\r\n",
      "[\"shouts\", \"turmoil\"]\t-0.197401535312193\r\n",
      "[\"disposing\", \"phosphorus\"]\t-0.19786175409476753\r\n",
      "[\"axe\", \"steering\"]\t-0.1989748456154889\r\n",
      "[\"clues\", \"socioeconomic\"]\t-0.20018723656568782\r\n",
      "[\"shells\", \"transitional\"]\t-0.20034170330064385\r\n",
      "[\"frost\", \"indiana\"]\t-0.2015296533533511\r\n",
      "[\"calamity\", \"impending\"]\t-0.20350364641322183\r\n",
      "[\"buffer\", \"terminals\"]\t-0.20552354174361334\r\n",
      "[\"compounded\", \"monitored\"]\t-0.2100024030209659\r\n",
      "[\"polarization\", \"printer\"]\t-0.2160580634487107\r\n",
      "[\"avenge\", \"efficiently\"]\t-0.21667253073909498\r\n",
      "[\"correlate\", \"drained\"]\t-0.21932552501530114\r\n",
      "[\"autobiography\", \"crazy\"]\t-0.22173725558315346\r\n",
      "[\"illuminated\", \"printer\"]\t-0.22197965158309724\r\n",
      "[\"diplomacy\", \"survivor\"]\t-0.2231291059971503\r\n",
      "[\"humiliation\", \"sack\"]\t-0.22425041584387917\r\n",
      "[\"kinship\", \"unfamiliar\"]\t-0.22543320222504148\r\n",
      "[\"inspector\", \"ordinances\"]\t-0.22945762675979348\r\n",
      "[\"articular\", \"experimentally\"]\t-0.23005316083390642\r\n",
      "[\"cooled\", \"freshness\"]\t-0.23172616842418195\r\n",
      "[\"concede\", \"hampered\"]\t-0.2349736098705823\r\n",
      "[\"illuminated\", \"polarization\"]\t-0.23514714816326746\r\n",
      "[\"discomfort\", \"sack\"]\t-0.2359508398270099\r\n",
      "[\"confidential\", \"consultant\"]\t-0.23627731392800902\r\n",
      "[\"individually\", \"sued\"]\t-0.2389333123267986\r\n",
      "[\"arkansas\", \"southeastern\"]\t-0.2398223922206708\r\n",
      "[\"implementing\", \"relies\"]\t-0.24096719643465572\r\n",
      "[\"excitation\", \"probe\"]\t-0.24799659975325594\r\n",
      "[\"lighting\", \"wasting\"]\t-0.2505854866577924\r\n",
      "[\"extracellular\", \"pancreas\"]\t-0.2542504282522134\r\n",
      "[\"clan\", \"kashmir\"]\t-0.254366725585451\r\n",
      "[\"ce\", \"est\"]\t-0.25519899458551226\r\n",
      "[\"holocaust\", \"individuality\"]\t-0.25560495882036643\r\n",
      "[\"dame\", \"linguistics\"]\t-0.2576311636094004\r\n",
      "[\"designer\", \"frost\"]\t-0.2586655316587161\r\n",
      "[\"inspect\", \"inspector\"]\t-0.26248847191125574\r\n",
      "[\"au\", \"ce\"]\t-0.27160230495092774\r\n",
      "[\"clubs\", \"sabha\"]\t-0.2727446553924146\r\n",
      "[\"tray\", \"whoever\"]\t-0.2775266604797696\r\n",
      "[\"dame\", \"jones\"]\t-0.2799023451134225\r\n",
      "[\"alzheimer's\", \"rating\"]\t-0.2808288382777394\r\n",
      "[\"bedside\", \"foe\"]\t-0.28143203779418485\r\n",
      "[\"cognizance\", \"interpreter\"]\t-0.28311583544456576\r\n",
      "[\"canons\", \"glasgow\"]\t-0.2901007034314636\r\n",
      "[\"coating\", \"negation\"]\t-0.29134382574502576\r\n",
      "[\"canons\", \"lutheran\"]\t-0.2917086847663463\r\n",
      "[\"precursor\", \"radioactive\"]\t-0.2923929949437485\r\n",
      "[\"buenos\", \"peru\"]\t-0.292431751833597\r\n",
      "[\"comprehended\", \"lawn\"]\t-0.2950341249927408\r\n",
      "[\"contradictory\", \"substantive\"]\t-0.29544257627055154\r\n",
      "[\"contamination\", \"mast\"]\t-0.2989955749857697\r\n",
      "[\"bucket\", \"lobby\"]\t-0.3000558405085481\r\n",
      "[\"designer\", \"indiana\"]\t-0.3017333828043913\r\n",
      "[\"mast\", \"sac\"]\t-0.30202981791573913\r\n",
      "[\"contradict\", \"ethic\"]\t-0.3077989072265286\r\n"
     ]
    }
   ],
   "source": [
    "!head -100 mrjob_542_ngrams_cosine_output_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this part of the assignment your will evaluate the success of you synonym detector.\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined\n",
    "by your measure in (2), and use the synonyms function in the accompanying\n",
    "python code:\n",
    "\n",
    "> ``nltk_synonyms.py``\n",
    "\n",
    "> Note: This will require installing the python nltk package:\n",
    "\n",
    "> http://www.nltk.org/install.html\n",
    "\n",
    "> and downloading its data with ``nltk.download()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download verifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download synonym script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget --quiet https://www.dropbox.com/sh/0cv65h44zylqwe3/AADbmhKuESCLaV_IntPhO2a2a/nltk_synonyms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synonym summary function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For each (word1,word2) pair, check to see if word1 is in the list,\n",
    "synonyms(word2), and vice-versa. If one of the two is a synonym of the other,\n",
    "then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of\n",
    "your detector across your 1,000 best guesses. Report the macro averages of these measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "\n",
    "from __future__ import division\n",
    "from nltk_synonyms import synonyms\n",
    "\n",
    "\"\"\"\n",
    "Utility function to print out the summary stats on the predictions made by\n",
    "the provided best pairs.\n",
    "\"\"\"\n",
    "def synonym_summary_stats(pairs_file_name):\n",
    "    with open(pairs_file_name, 'r') as pairs_file:\n",
    "        pairs = [eval(line) for line in pairs_file]\n",
    "\n",
    "    predicted_synonyms = {}\n",
    "\n",
    "    # Identify the predicted synonyms represented by the best scoring pairs.\n",
    "\n",
    "    for word1, word2 in pairs:\n",
    "        if word1 not in predicted_synonyms:\n",
    "            predicted_synonyms[word1] = set([word2])\n",
    "        else:\n",
    "            predicted_synonyms[word1].add(word2)\n",
    "\n",
    "        if word2 not in predicted_synonyms:\n",
    "            predicted_synonyms[word2] = set([word1])\n",
    "        else:\n",
    "            predicted_synonyms[word2].add(word1)\n",
    "\n",
    "    # Load the basis words.\n",
    "\n",
    "    with open('ngrams_basis.txt', 'r') as basis_file:\n",
    "        vocabulary = set([row[0] for row in csv.reader(basis_file, delimiter = '\\t')])\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # Print the recall/precision/f1 for each word\n",
    "\n",
    "    row_format = '{:<15s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}'\n",
    "\n",
    "    print 'Words where there are >0 true positives:\\n'\n",
    "\n",
    "    print row_format.format(\n",
    "        'word', 'true_pos', 'false_pos', 'false_neg', 'precision', 'recall', 'f1')\n",
    "\n",
    "    print '-------------------------------------------------------------------------------------'\n",
    "\n",
    "    for word, predictions in predicted_synonyms.iteritems():\n",
    "        true_synonyms = set(synonyms(word))\n",
    "\n",
    "        true_pos = len(true_synonyms.intersection(predictions))\n",
    "        false_pos = len(predictions.difference(true_synonyms))\n",
    "        false_neg = len(true_synonyms.difference(predictions))\n",
    "\n",
    "        if true_pos == 0:\n",
    "            continue\n",
    "\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        precisions.append(precision)\n",
    "        precision_string = '{:6.3f}'.format(precision)\n",
    "\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        recalls.append(recall)\n",
    "        recall_string = '{:6.3f}'.format(recall)\n",
    "\n",
    "        if precision > 0 or recall > 0:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            f1_string = '{:6.3f}'.format(f1)\n",
    "        else:\n",
    "            f1_string = None\n",
    "\n",
    "        print row_format.format(\n",
    "            word, str(true_pos), str(false_pos), str(false_neg),\n",
    "            precision_string, recall_string, f1_string)\n",
    "\n",
    "    # Print the macro stats for the whole set of words.\n",
    "\n",
    "    precision_macro = numpy.mean(precisions)\n",
    "    recall_macro = numpy.mean(recalls)\n",
    "\n",
    "    if precision_macro > 0 or recall_macro > 0:\n",
    "        f1_macro = 2 * 2 * precision_macro * recall_macro / (precision_macro + recall_macro)\n",
    "    else:\n",
    "        f1_macro = 0\n",
    "\n",
    "    print '\\n\\nSummary stats'\n",
    "    print '--------------------------'\n",
    "    print '{:<17s} {:2.4f}'.format('Precision:', precision_macro)\n",
    "    print '{:<17s} {:2.4f}'.format('Recall:', recall_macro)\n",
    "    print '{:<17s} {:2.4f}'.format('F1:', f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get log-jaccard stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words where there are >0 true positives:\n",
      "\n",
      "word             true_pos false_pos false_neg precision    recall        f1\n",
      "-------------------------------------------------------------------------------------\n",
      "benevolent              1         1        10     0.500     0.091     0.154\n",
      "provoked                1         2        22     0.333     0.043     0.077\n",
      "charitable              1         1         6     0.500     0.143     0.222\n",
      "wept                    1         2         1     0.333     0.500     0.400\n",
      "sinners                 1         1         1     0.500     0.500     0.500\n",
      "\n",
      "\n",
      "Summary stats\n",
      "--------------------------\n",
      "Precision:        0.4333\n",
      "Recall:           0.2554\n",
      "F1:               0.6428\n"
     ]
    }
   ],
   "source": [
    "!head -1000 mrjob_542_ngrams_jaccard_output_sorted.txt | cut -f 1 > jaccard1000.txt\n",
    "synonym_summary_stats('jaccard1000.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get log-cosine stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words where there are >0 true positives:\n",
      "\n",
      "word             true_pos false_pos false_neg precision    recall        f1\n",
      "-------------------------------------------------------------------------------------\n",
      "transparent             1         0        16     1.000     0.059     0.111\n",
      "sinners                 1         3         1     0.250     0.500     0.333\n",
      "aggravated              1         2         5     0.333     0.167     0.222\n",
      "tumult                  1         7         9     0.125     0.100     0.111\n",
      "turmoil                 1         5         6     0.167     0.143     0.154\n",
      "crystalline             1         2         5     0.333     0.167     0.222\n",
      "provoked                2         3        21     0.400     0.087     0.143\n",
      "wept                    1         1         1     0.500     0.500     0.500\n",
      "spoils                  1         2        57     0.333     0.017     0.033\n",
      "\n",
      "\n",
      "Summary stats\n",
      "--------------------------\n",
      "Precision:        0.3824\n",
      "Recall:           0.1932\n",
      "F1:               0.5135\n"
     ]
    }
   ],
   "source": [
    "!head -1000 mrjob_542_ngrams_cosine_output_sorted.txt | cut -f 1 > cosine1000.txt\n",
    "synonym_summary_stats('cosine1000.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.5.1 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts.\n",
    "\n",
    "> Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> ```\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.6 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are many good ways to build our synonym detectors, so for optional homework,\n",
    "measure co-occurrence by (left/right/all) consecutive words only,\n",
    "or make stripes according to word co-occurrences with the accompanying\n",
    "2-, 3-, or 4-grams (note here that your output will no longer\n",
    "be interpretable as a network) inside of the 5-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5.7 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Once again, benchmark your top 10,000 associations (as in 5.5), this time for your\n",
    "results from 5.6. Has your detector improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 4,
   "toc_window_display": true
  },
  "toc_position": {
   "left": "1623.83px",
   "right": "20px",
   "top": "121px",
   "width": "200px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
