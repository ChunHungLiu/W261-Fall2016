{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student**: Minhchau Dang\n",
    "* **Email Address**: minhchau.dang@berkeley.edu\n",
    "* **Course**: 2016-0111 DATASCI W261: Machine Learning at Scale\n",
    "* **Section**: Spring 2016, Section 2\n",
    "* **Assignment**: Homework 0, Week 0\n",
    "* **Submission Date**: Month 0, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires some nbextensions.\n",
    "\n",
    "* [toc2](https://github.com/ipython-contrib/IPython-notebook-extensions/tree/master/nbextensions/usability/toc2) provides a button to create a floating table of contents\n",
    "* [toggle_all_line_numbers](https://github.com/ipython-contrib/IPython-notebook-extensions/tree/master/nbextensions/usability/toggle_all_line_numbers) provides a button to see line numbers for all code cells\n",
    "* [autosaveclasses](https://github.com/holatuwol/jupyter-magic/tree/master/nbextensions/autosaveclasses.js) avoids usage of `%%writefile` (cells with a class definition are saved to disk when run)\n",
    "\n",
    "If they are not yet installed, run the following cell and restart the notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "IPYTHON_PROFILE_HOME=$(ipython locate)\n",
    "\n",
    "nbextdl() {\n",
    "    if [ ! -f $IPYTHON_PROFILE_HOME/nbextensions/$2/$3 ]; then\n",
    "        mkdir -p $IPYTHON_PROFILE_HOME/nbextensions/$2\n",
    "        curl --silent -L \\\n",
    "            \"https://raw.githubusercontent.com/$1/master/nbextensions/$2/$3\" \\\n",
    "            > \"$IPYTHON_PROFILE_HOME/nbextensions/$2/$3\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2 main.js\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2 main.css\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2 icon.png\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toc2 image.png\n",
    "\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toggle_all_line_numbers main.js\n",
    "nbextdl ipython-contrib/IPython-notebook-extensions usability/toggle_all_line_numbers icon.png\n",
    "\n",
    "nbextdl holatuwol/jupyter-magic . autosaveclasses.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoload the extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['base/js/utils'], function(utils) {\n",
       "    utils.load_extensions('usability/toc2/main');\n",
       "    utils.load_extensions('usability/toggle_all_line_numbers/main');\n",
       "    utils.load_extensions('autosaveclasses');\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'], function(utils) {\n",
    "    utils.load_extensions('usability/toc2/main');\n",
    "    utils.load_extensions('usability/toggle_all_line_numbers/main');\n",
    "    utils.load_extensions('autosaveclasses');\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In mathematics, computer science, economics, or management science what is mathematical optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Give an example of a optimization problem that you have worked with directly or that your organization has worked on. Please describe the objective function and the decision variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Was the project successful (deployed in the real world)? Describe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.1 Optimization Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconstrained univariate optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f : \\mathbb{R} \\rightarrow \\mathbb{R}$ in class $C^1$ and $C^2$ (its first derivative and second derivative are continuous functions). Let $\\nabla f$ be the gradient function (first derivative) and let $\\nabla^2 f$ be the gradient of the gradient function (second derivative).\n",
    "\n",
    "Define the local minimum $x_0$ as a value satisfying the condition that there exists some neighborhood $\\mathcal{N}$ consisting of all the points within $\\epsilon > 0$ of $x_0$ for which $\\forall x \\in \\mathcal{N}: f(x_0) < f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For unconstrained univariate optimization what are the first order Necessary Conditions for Optimality (FOC)? Give a mathematical definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $f(x_0)$ is a local minimum of $f$, then $\\nabla f(x_0) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  What are the second order optimality conditions (SOC)? Give a mathematical defintion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $f(x_0)$ is a local minimum of $f$, then $\\nabla^2 f(x_0) > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Also in python, plot the univariate function $x^3 -12x^2-6$ defined over the real domain -6 to +6. Also plot its corresponding first and second derivative functions. Eyeballing these graphs, identify candidate optimal points and then classify them as local minimums or maximums. Highlight and label these points in your graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4oAAAEbCAYAAACcKHo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRICjMInI3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f3ad91350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "\"\"\"\n",
    "Utility function for plotting the line.\n",
    "\"\"\"\n",
    "def plot_line(subplot, x_values, y_values, function_name, function_value):\n",
    "    subplot.plot(x_values, y_values, color = 'gray')\n",
    "\n",
    "    subplot.grid(True)\n",
    "    subplot.set_title('$' + function_name + ' = ' + function_value + '$')\n",
    "    subplot.set_xlabel('$x$')\n",
    "    subplot.set_ylabel('$' + function_name + '$')\n",
    "\n",
    "\"\"\"\n",
    "Utility function for adding a boxed annotation.\n",
    "\"\"\"\n",
    "def annotate_plot(subplot, point, text, position):\n",
    "    subplot.annotate(\n",
    "        text, xy = point, xytext = position,\n",
    "        bbox = {'boxstyle': 'round', 'fc': 'white'},\n",
    "        arrowprops = {'arrowstyle': '->'})\n",
    "\n",
    "# Generate the x-values and initialize the subplots\n",
    "\n",
    "x0 = numpy.linspace(-6, 6, 50)    \n",
    "fig = pyplot.figure(figsize = (15, 4))\n",
    "subplots = [fig.add_subplot(1, 3, i + 1) for i in range(3)]\n",
    "\n",
    "# Plot the function: x^3 - 12x^2 - 6\n",
    "\n",
    "y0 = [x**3 - 12 * x**2 - 6 for x in x0]\n",
    "plot_line(subplots[0], x0, y0, 'f(x)', 'x^3 - 12x^2 - 6')\n",
    "annotate_plot(subplots[0], (0, -6), '$\\\\forall x \\in \\mathcal{N} : f(0) > f(x)$', (-1.5, -150))\n",
    "\n",
    "# Plot the gradient function: 3x^2 - 24x\n",
    "\n",
    "y1 = [3 * x**2 - 24 * x for x in x0]\n",
    "plot_line(subplots[1], x0, y1, '\\\\nabla f(x)', '3x^2 - 24x')\n",
    "annotate_plot(subplots[1], (0, 0), '$\\\\nabla f(0) = 0$', (0, 100))\n",
    "\n",
    "# Plot the gradient function: 3x^2 - 24x\n",
    "\n",
    "y2 = [6 * x - 24 for x in x0]\n",
    "plot_line(subplots[2], x0, y2, '\\\\nabla^2 f(x)', '6x - 24')\n",
    "annotate_plot(subplots[2], (0, -24), '$\\\\nabla^2 f(0) < 0$', (-3, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Justify your responses using the FOC and SOC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconstrained multivariate optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For unconstrained multi-variate optimization what are the first order Necessary Conditions for Optimality (FOC). Give a mathematical definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What are the second order optimality conditions (SOC)? Give a mathematical definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is the Hessian matrix in this context?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Taking $x=1$ as the first approximation ($x_{t_1}$) of a root of $x^3 + 2x -4 = 0$, use the Newton-Raphson method to calculate the second approximation (denoted as $x_{t_2}$) of this root. (Hint: the solution is $x_{t_2} = 1.2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.3 Convex Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What makes an optimization problem convex?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  What are the first order Necessary Conditions for Optimality in convex optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What are the second order optimality conditions for convex optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Are both necessary to determine the maximum or minimum of candidate optimal solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill in the BLANKS here: Convex minimization, a subfield of optimization, studies the problem of minimizing BLANK functions over BLANK sets. The BLANK property can make optimization in some sense \"easier\" than the general case - for example, any local minimum must be a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The learning objective function for weighted ordinary least squares (WOLS) (aka weight linear regression) is defined as follows:\n",
    "\n",
    "> $$0.5 \\sum_{i} (weight)_i \\cdot (\\mathbf{W} \\cdot \\mathbf{X}_i - y_i)^2$$\n",
    "\n",
    "> Where training set consists of input variables $\\mathbf{X}$ (in vector form) and a target variable $y$, and $\\mathbf{X}$ is the vector of coefficients for the linear regression model.\n",
    "\n",
    "> Derive the gradient for this weighted OLS by hand; showing each step and also explaining each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can use the same approach as documented in the class notes for CS 229 at Stanford University ([reference](http://cs229.stanford.edu/notes/cs229-notes1.pdf)), which computes each element of the gradient vector separately.\n",
    "\n",
    "First, if we take the partial derivative with respect to the $j$-th element of the cost vector and apply the chain rule, we have the following:\n",
    "\n",
    "$$0.5 \\sum_{i} (weight)_i \\cdot ((2) (\\mathbf{W} \\cdot \\mathbf{X}_i - y_i)) \\cdot\n",
    "    \\frac{\\partial}{\\partial \\mathbf{W}_j} (\\mathbf{W} \\cdot \\mathbf{X}_i - y_i)$$\n",
    "\n",
    "Simplifying by multiplying the (0.5) and the (2), we have the following:\n",
    "\n",
    "$$\\sum_{i} (weight)_i \\cdot (\\mathbf{W} \\cdot \\mathbf{X}_i - y_i) \\cdot\n",
    "    \\frac{\\partial}{\\partial \\mathbf{W}_j} (\\mathbf{W} \\cdot \\mathbf{X}_i - y_i)$$\n",
    "\n",
    "Observe that when we take the partial derivative of $\\mathbf{W} \\cdot \\mathbf{X}_i - y_i)$ with respect to $\\mathbf{W}_j$, most of the weights in $\\mathbf{W}$ are zero. This results in us only being left with $\\mathbf{X}_{ij}$, or the $j$-th element of $\\mathbf{X}$ (or simply 1 for the intercept term).\n",
    "\n",
    "This simplifies to the following:\n",
    "\n",
    "$$\\sum_{i} (weight)_i \\cdot (\\mathbf{W} \\cdot \\mathbf{X}_i - y_i) \\cdot \\mathbf{X}_{ij}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate HW6.5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generate one million datapoints just like in the following notebook: \n",
    "\n",
    "> http://nbviewer.ipython.org/urls/dl.dropbox.com/s/kritdm3mo1daolj/MrJobLinearRegressionGD.ipynb\n",
    "\n",
    "> Weight each example as follows: $weight(x) = abs(x^{-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 LinearRegression.csv\r\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "\n",
    "if not os.path.isfile('LinearRegression.csv'):\n",
    "    size = 1000 * 1000\n",
    "    x = numpy.random.uniform(-4, 4, size)\n",
    "    y = x * 1.0 - 4 + numpy.random.normal(0, 0.5, size)\n",
    "    weights = numpy.divide(numpy.ones(size), numpy.abs(x))\n",
    "\n",
    "    data = zip(y, x, weights)\n",
    "    numpy.savetxt('LinearRegression.csv', data, delimiter = ',')\n",
    "\n",
    "# Confirm that we created the file\n",
    "\n",
    "!wc -l LinearRegression.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HW6.5 job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Write a MapReduce job in MRJob to do the training at scale of a weighted OLS model using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawProtocol\n",
    "\n",
    "class WeightedOrdinaryLeastSquaresJob(MRJob):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load the learning factor.\n",
    "    \"\"\"\n",
    "    def configure_options(self):\n",
    "        super(WeightedOrdinaryLeastSquaresJob, self).configure_options()\n",
    "\n",
    "        self.add_passthrough_option(\n",
    "            '--learning-factor', type = 'float', default = 0.001)\n",
    "    \n",
    "    \"\"\"\n",
    "    Load the regression model from the previous iteration and initialize the\n",
    "    partial sums.\n",
    "    \"\"\"\n",
    "    def mapper_init(self):\n",
    "        self.load_model()\n",
    "        self.gradient = [0.0] * len(self.coef)\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the error term and use the weighted error value to update the tally.\n",
    "    \"\"\"\n",
    "    def mapper(self, _, line):\n",
    "        row = csv.reader([line]).next()\n",
    "        \n",
    "        # First element is y, all middle elements are part of the vector x_i,\n",
    "        # and the last element is the weight.\n",
    "\n",
    "        y = float(row[0])\n",
    "        x_i = [1.0] + [float(x) for x in row[1:-1]]\n",
    "        weight = float(row[-1])\n",
    "        \n",
    "        # Compute the value predicted by the model by computing the dot product.\n",
    "        # For now, avoid using numpy due to MRJob import issues.\n",
    "  \n",
    "        dot_product = sum([coef_j * x_ij for coef_j, x_ij in zip(self.coef, x_i)])\n",
    "        error = dot_product - y\n",
    "\n",
    "        # Update the gradient tally.\n",
    "\n",
    "        for j in range(len(self.gradient)):\n",
    "            self.gradient[j] += weight * error * x_i[j]\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the computed tally.\n",
    "    \"\"\"\n",
    "    def mapper_final(self):\n",
    "        for j in range(len(self.gradient)):\n",
    "            yield j, self.gradient[j]\n",
    "\n",
    "    \"\"\"\n",
    "    Load the regression model from the previous iteration.\n",
    "    \"\"\"\n",
    "    def reducer_init(self):\n",
    "        self.load_model()\n",
    "    \n",
    "    \"\"\"\n",
    "    Yield the new coefficients by subtracting the gradient change from the\n",
    "    original coefficient.\n",
    "    \"\"\"\n",
    "    def reducer(self, j, gradients):        \n",
    "        total_gradient = sum(gradients)\n",
    "        adjusted_gradient = self.options.learning_factor * total_gradient\n",
    "\n",
    "        new_coef = self.coef[j] - adjusted_gradient\n",
    "        yield j, new_coef\n",
    "\n",
    "    \"\"\"\n",
    "    Load the regression model from the previous iteration.\n",
    "    \"\"\"\n",
    "    def load_model(self):\n",
    "\n",
    "        # The model is not guaranteed to be in order since it can be emitted\n",
    "        # by multiple reducers, so pad the array if we get an index that is\n",
    "        # too far into the array.\n",
    "        \n",
    "        self.coef = []\n",
    "        \n",
    "        with open('model.txt', 'r') as model_file:\n",
    "            for key, value in csv.reader(model_file):\n",
    "                index = int(key)\n",
    "                \n",
    "                for i in range(len(self.coef), index + 1):\n",
    "                    self.coef.append(0.0)\n",
    "            \n",
    "                self.coef[index] = float(value)\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    WeightedOrdinaryLeastSquaresJob().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a generic driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "class ConvergingModelDriver:\n",
    "\n",
    "    \"\"\"\n",
    "    Stores the given model to a file.\n",
    "    \"\"\"\n",
    "    def store_model(self, file_name, model):\n",
    "        with open(file_name, 'w') as model_file:\n",
    "            for key, point in model.iteritems():\n",
    "                print >> model_file, str(key) + ',' + ','.join([str(x) for x in point])\n",
    "\n",
    "    \"\"\"\n",
    "    Iterates until the threshold for convergence has been satisfied.\n",
    "    \"\"\"\n",
    "    def run(self, runner_type, input_file, output_folder, threshold):\n",
    "\n",
    "        # Create the output directory locally.\n",
    "        \n",
    "        if os.path.isdir(output_folder):\n",
    "            shutil.rmtree(output_folder)\n",
    "        \n",
    "        os.mkdir(output_folder)\n",
    "        \n",
    "        # Initialize the model.\n",
    "\n",
    "        pre_model = None\n",
    "        post_model = self.get_initial_model()\n",
    "\n",
    "        # Iterate until we have converged.\n",
    "\n",
    "        converged = False\n",
    "        iteration = 0\n",
    "\n",
    "        self.log_iteration(0, post_model, None)\n",
    "        \n",
    "        time_start = time.time()\n",
    "        base_args = ['-r', runner_type, '--strict-protocols', '--file=model.txt', input_file]\n",
    "        \n",
    "        while not converged:\n",
    "            iteration += 1\n",
    "            pre_model = post_model\n",
    "\n",
    "            # Write the model.txt file for the next iteration.\n",
    "\n",
    "            iteration_file_name = '%s/%04d.txt' % (output_folder, iteration)\n",
    "\n",
    "            self.store_model(iteration_file_name, post_model)\n",
    "            shutil.copyfile(iteration_file_name, 'model.txt')\n",
    "\n",
    "            # Run the next iteration.\n",
    "\n",
    "            iteration_output_folder = '%s/%04d' % (output_folder, iteration)\n",
    "\n",
    "            iteration_args = ['--output-dir=' + iteration_output_folder]\n",
    "            \n",
    "            mr_job = self.get_job(base_args + iteration_args)\n",
    "\n",
    "            with mr_job.make_runner() as runner:\n",
    "                runner.run()\n",
    "\n",
    "                # Retrieve the model from the streaming output.\n",
    "                \n",
    "                post_model = {}\n",
    "\n",
    "                for line in runner.stream_output():\n",
    "                    key, point = mr_job.parse_output_line(line)\n",
    "                    \n",
    "                    if isinstance(point, float):\n",
    "                        point = [point]\n",
    "                        \n",
    "                    post_model[key] = point\n",
    "\n",
    "                # Account for when some class no longer gets emitted\n",
    "\n",
    "                for key, point in pre_model.iteritems():\n",
    "                    if key not in post_model:\n",
    "                        post_model[key] = point\n",
    "\n",
    "            # Log iteration results and check for convergence.\n",
    "\n",
    "            maximum_change = self.get_maximum_change(pre_model, post_model)\n",
    "            self.log_iteration(iteration, post_model, maximum_change)\n",
    "            converged = maximum_change <= threshold\n",
    "\n",
    "        time_end = time.time()\n",
    "        duration = time_end - time_start\n",
    "\n",
    "        print 'Converged in', iteration, 'iteration(s), which required', duration, 'second(s)'\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the maximum change for any feature in the model.\n",
    "    \"\"\"\n",
    "    def get_maximum_change(self, pre_model, post_model):\n",
    "        best_point_difference = 0\n",
    "\n",
    "        for key, pre_point in pre_model.iteritems():\n",
    "            post_point = post_model[key]\n",
    "\n",
    "            point_difference = numpy.array(pre_point) - numpy.array(post_point)\n",
    "            max_point_difference = max(numpy.abs(point_difference))\n",
    "\n",
    "            if max_point_difference > best_point_difference:\n",
    "                best_point_difference = max_point_difference\n",
    "\n",
    "        return best_point_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HW6.5 driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "from ConvergingModelDriver import ConvergingModelDriver\n",
    "from WeightedOrdinaryLeastSquaresJob import WeightedOrdinaryLeastSquaresJob\n",
    "\n",
    "class WeightedOrdinaryLeastSquaresDriver(ConvergingModelDriver):\n",
    "\n",
    "    \"\"\"\n",
    "    For reproducibility, we'll start at (0,0)\n",
    "    \"\"\"\n",
    "    def get_initial_model(self):\n",
    "        return {\n",
    "            0: [0.0],\n",
    "            1: [0.0]\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "    Return a job with a maximum weight set to 1000 and a learning rate set\n",
    "    to 2 * 10^-7\n",
    "    \"\"\"\n",
    "    def get_job(self, iteration_args):\n",
    "        learning_factor = 1.0 / (1000.0 * 1000.0 * 20)\n",
    "        \n",
    "        extra_args = [\n",
    "            '--learning-factor=' + str(learning_factor)\n",
    "        ]\n",
    "        \n",
    "        jobs_args = iteration_args + extra_args\n",
    "        return WeightedOrdinaryLeastSquaresJob(args = jobs_args)\n",
    "\n",
    "    \"\"\"\n",
    "    Logs the model.\n",
    "    \"\"\"\n",
    "    def log_iteration(self, iteration, model, maximum_change):\n",
    "        print '%04d\\t%f\\t%f' % (iteration, model[0][0], model[1][0])\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    driver = WeightedOrdinaryLeastSquaresDriver()\n",
    "    driver.run(sys.argv[1], sys.argv[2], sys.argv[3], float(sys.argv[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run HW6.5 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\t0.000000\t0.000000\n",
      "No handlers could be found for logger \"mrjob.local\"\n",
      "0001\t-1.187683\t0.100324\n",
      "0002\t-2.014406\t0.190528\n",
      "0003\t-2.589871\t0.271652\n",
      "0004\t-2.990438\t0.344620\n",
      "0005\t-3.269263\t0.410261\n",
      "0006\t-3.463344\t0.469316\n",
      "0007\t-3.598437\t0.522450\n",
      "0008\t-3.692470\t0.570259\n",
      "0009\t-3.757922\t0.613279\n",
      "0010\t-3.803479\t0.651992\n",
      "0011\t-3.835188\t0.686828\n",
      "0012\t-3.857257\t0.718177\n",
      "0013\t-3.872618\t0.746389\n",
      "0014\t-3.883308\t0.771778\n",
      "0015\t-3.890747\t0.794626\n",
      "0016\t-3.895924\t0.815188\n",
      "0017\t-3.899526\t0.833693\n",
      "0018\t-3.902032\t0.850346\n",
      "0019\t-3.903776\t0.865334\n",
      "0020\t-3.904988\t0.878822\n",
      "0021\t-3.905831\t0.890960\n",
      "0022\t-3.906417\t0.901885\n",
      "0023\t-3.906824\t0.911716\n",
      "0024\t-3.907107\t0.920564\n",
      "0025\t-3.907303\t0.928527\n",
      "0026\t-3.907439\t0.935693\n",
      "0027\t-3.907533\t0.942143\n",
      "0028\t-3.907598\t0.947947\n",
      "0029\t-3.907643\t0.953170\n",
      "0030\t-3.907674\t0.957871\n",
      "0031\t-3.907695\t0.962102\n",
      "0032\t-3.907710\t0.965910\n",
      "0033\t-3.907720\t0.969336\n",
      "0034\t-3.907726\t0.972420\n",
      "0035\t-3.907730\t0.975196\n",
      "0036\t-3.907733\t0.977694\n",
      "0037\t-3.907735\t0.979941\n",
      "0038\t-3.907736\t0.981964\n",
      "0039\t-3.907737\t0.983785\n",
      "0040\t-3.907737\t0.985424\n",
      "0041\t-3.907737\t0.986898\n",
      "0042\t-3.907737\t0.988225\n",
      "0043\t-3.907737\t0.989420\n",
      "0044\t-3.907737\t0.990495\n",
      "0045\t-3.907737\t0.991462\n",
      "Converged in 45 iteration(s), which required 453.469545126 second(s)\n"
     ]
    }
   ],
   "source": [
    "!python WeightedOrdinaryLeastSquaresDriver.py local LinearRegression.csv mrjob_65_output 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.5a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sample 1% of the data in MapReduce and use the sampled dataset to train a (weighted if available in SciKit-Learn) linear regression model locally using  SciKit-Learn (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a job to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol\n",
    "\n",
    "class RandomSampleJob(MRJob):\n",
    "    \n",
    "    OUTPUT_PROTOCOL = RawValueProtocol\n",
    "\n",
    "    \"\"\"\n",
    "    Load the sampling factor.\n",
    "    \"\"\"\n",
    "    def configure_options(self):\n",
    "        super(RandomSampleJob, self).configure_options()\n",
    "\n",
    "        self.add_passthrough_option(\n",
    "            '--sampling-factor', type = 'float', default = 0.01)\n",
    "\n",
    "    \"\"\"\n",
    "    Yield the line with the sampling probability.\n",
    "    \"\"\"\n",
    "    def mapper(self, _, line):\n",
    "        if random.random() <= self.options.sampling_factor:\n",
    "            yield None, line\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    RandomSampleJob().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the sampling job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf mrjob_65a_output\n",
    "!python RandomSampleJob.py -r local \\\n",
    "    --strict-protocols \\\n",
    "    --sampling-factor=0.01 \\\n",
    "    --output-dir=mrjob_65a_output \\\n",
    "    LinearRegression.csv \\\n",
    "    --no-output \\\n",
    "    > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9953 LinearRegression.sample.csv\r\n"
     ]
    }
   ],
   "source": [
    "!cat mrjob_65a_output/* > LinearRegression.sample.csv\n",
    "!wc -l LinearRegression.sample.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check HW6.5 against scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 6.5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the resulting weighted linear regression model versus the original model that you used to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comment on your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.5.1 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using MRJob and in Python, plot the error surface for the weighted linear regression model using a heatmap and contour plot. Also plot the current model in the original domain space.  (Plot them side by side if possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the path to convergence (during training) for the weighted linear regression model in plot error space and in the original domain space. Make sure to label your plots with iteration numbers, function, model space versus original domain space, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comment on convergence and on the mean squared error using your weighted OLS algorithm on the weighted dataset versus using the weighted OLS algorithm on the uniformly weighted dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.6 Clean up notebook for GMM via EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the following notebook as a starting point:\n",
    "\n",
    "> http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/0t7985e40fovlkw/EM-GMM-MapReduce%20Design%201.ipynb \n",
    "\n",
    "> Improve this notebook as follows:\n",
    "> - Add in equations into the notebook (not images of equations) \n",
    "> - Number the equations\n",
    "> - Make sure the equation notation matches the code and the code and comments refer to the equations numbers\n",
    "> - Comment the code\n",
    "> - Rename/Reorganize the code to make it more readable\n",
    "> - Rerun the examples similar graphics (or possibly better graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6.7 Implement Bernoulli Mixture Model via EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HW6.7 job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Implement the EM clustering algorithm to determine Bernoulli Mixture Model for discrete data in MRJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class BernoulliMixtureModelJob(MRJob):\n",
    "\n",
    "    \"\"\"\n",
    "    Load the smoothing factor.\n",
    "    \"\"\"\n",
    "    def configure_options(self):\n",
    "        super(BernoulliMixtureModelJob, self).configure_options()\n",
    "\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothing-factor', type = 'float', default = 0.0001)\n",
    "    \n",
    "    \"\"\"\n",
    "    Load the Bernoulli Mixture Model from the previous iteration and initialize\n",
    "    the class counts (for the priors) and the weighted feature tallies.\n",
    "    \"\"\"\n",
    "    def mapper_init(self):\n",
    "        self.load_model()\n",
    "\n",
    "        self.total_examples = 0\n",
    "        self.class_examples = []\n",
    "        self.weighted_true = []\n",
    "        self.weighted_false = []\n",
    "        \n",
    "        # There is a strange pass by reference issue in initializing 2D arrays\n",
    "        # using the multiplication operator, so iterate and append 1D arrays.\n",
    "        \n",
    "        for i in range(self.class_count):\n",
    "            self.class_examples.append(0)\n",
    "            self.weighted_true.append([0.0] * self.feature_count)\n",
    "            self.weighted_false.append([0.0] * self.feature_count)\n",
    "        \n",
    "    \"\"\"\n",
    "    Compute the probability for each class and update our internal tallies of\n",
    "    how many true/false values on each feature for each class.\n",
    "    \"\"\"\n",
    "    def mapper(self, _, line):\n",
    "        features = [bool(int(x)) for x in csv.reader([line]).next()]\n",
    "        \n",
    "        # First, compute the log likelihood that the feature is in any given\n",
    "        # feature class.\n",
    "        \n",
    "        log_likelihoods = []\n",
    "        \n",
    "        for class_prior, likelihoods in zip(self.class_priors, self.likelihoods):\n",
    "            if class_prior == 0.0:\n",
    "                log_likelihoods.append(float('-inf'))\n",
    "                continue\n",
    "            \n",
    "            log_likelihood = math.log(class_prior)\n",
    "        \n",
    "            for feature, likelihood in zip(features, likelihoods):\n",
    "                if feature:\n",
    "                    log_likelihood += math.log(likelihood)\n",
    "                else:\n",
    "                    log_likelihood += math.log(1 - likelihood)\n",
    "            \n",
    "            log_likelihoods.append(log_likelihood)\n",
    "        \n",
    "        # Identify the maximum probability value and update the class example\n",
    "        # count for the corresponding class.\n",
    "        \n",
    "        max_log_likelihood = max(log_likelihoods)\n",
    "        class_id = log_likelihoods.index(max_log_likelihood)\n",
    "\n",
    "        self.total_examples += 1\n",
    "        self.class_examples[class_id] += 1\n",
    "        \n",
    "        # Shift the log likelihoods to avoid getting an underflow when we\n",
    "        # convert them to exponents. Note that everything is negative, so you\n",
    "        # will want to subtract.\n",
    "        \n",
    "        shifted_log_likelihoods = [x - max_log_likelihood for x in log_likelihoods]\n",
    "        \n",
    "        # Identify the numerators by exponentiating all the values. Compute\n",
    "        # the denominator by adding the numerators together.\n",
    "        \n",
    "        numerators = [math.exp(x) for x in shifted_log_likelihoods]\n",
    "        denominator = sum(numerators)\n",
    "        \n",
    "        # Compute the class probabilities so that we can tally the weighted\n",
    "        # feature occurrencies.\n",
    "\n",
    "        for i in range(self.class_count):\n",
    "            class_probability = numerators[i] / denominator\n",
    "            \n",
    "            for j in range(self.feature_count):\n",
    "                if features[j]:\n",
    "                    self.weighted_true[i][j] += class_probability\n",
    "                else:\n",
    "                    self.weighted_false[i][j] += class_probability\n",
    "\n",
    "    \"\"\"\n",
    "    Emit the weighted probabilities.\n",
    "    \"\"\"\n",
    "    def mapper_final(self):\n",
    "        for i in range(self.class_count):\n",
    "            class_id = self.class_ids[i]\n",
    "            \n",
    "            class_summary = {\n",
    "                'class_examples': self.class_examples[i],\n",
    "                'total_examples': self.total_examples,\n",
    "                'weighted_true': self.weighted_true[i],\n",
    "                'weighted_false': self.weighted_false[i]\n",
    "            }\n",
    "\n",
    "            yield class_id, class_summary\n",
    "\n",
    "    \"\"\"\n",
    "    Load the Bernoulli Mixture Model from the previous iteration.\n",
    "    \"\"\"\n",
    "    def reducer_init(self):\n",
    "        self.load_model()\n",
    "\n",
    "    \"\"\"\n",
    "    Combine the summaries for each class in order to compute the new priors and\n",
    "    conditional probabilities / likelihoods.\n",
    "    \"\"\"\n",
    "    def reducer(self, class_id, class_summaries):\n",
    "        class_examples = 0\n",
    "        total_examples = 0\n",
    "        total_weighted_true = [0.0] * self.feature_count\n",
    "        total_weighted_false = [0.0] * self.feature_count\n",
    "        \n",
    "        # Combine the counts and weighted counts.\n",
    "        \n",
    "        for class_summary in class_summaries:\n",
    "            class_examples += class_summary['class_examples']\n",
    "            total_examples += class_summary['total_examples']\n",
    "            \n",
    "            for i in range(self.feature_count):\n",
    "                total_weighted_true[i] += class_summary['weighted_true'][i]\n",
    "                total_weighted_false[i] += class_summary['weighted_false'][i]\n",
    "        \n",
    "        # Compute the priors and likelihoods\n",
    "        \n",
    "        class_prior = float(class_examples) / total_examples\n",
    "        likelihoods = []\n",
    "        \n",
    "        for weighted_true, weighted_false in zip(total_weighted_true, total_weighted_false):\n",
    "            weighted_true = weighted_true + self.options.smoothing_factor\n",
    "            weighted_total = (weighted_true + weighted_false) + (self.options.smoothing_factor * self.class_count)\n",
    "            \n",
    "            likelihood = weighted_true / weighted_total\n",
    "            likelihoods.append(likelihood)\n",
    "\n",
    "        # Yield the priors concatenated to the likelihoods as the model for this class\n",
    "            \n",
    "        yield class_id, [class_prior] + likelihoods\n",
    "        \n",
    "    \"\"\"\n",
    "    Load the Bernoulli Mixture Model from the previous iteration.\n",
    "    \"\"\"\n",
    "    def load_model(self):\n",
    "        self.class_ids = []\n",
    "        self.class_priors = []\n",
    "        self.likelihoods = []\n",
    "        \n",
    "        # Initialize the class IDs, the priors, and the per-class likelihoods.\n",
    "        \n",
    "        with open('model.txt', 'r') as model_file:\n",
    "            for row in csv.reader(model_file):\n",
    "                class_id = row[0]\n",
    "                class_prior = float(row[1])\n",
    "                likelihoods = [float(x) for x in row[2:]]\n",
    "                \n",
    "                self.class_ids.append(class_id)\n",
    "                self.class_priors.append(class_prior)\n",
    "                self.likelihoods.append(likelihoods)\n",
    "        \n",
    "        # For convenience\n",
    "        \n",
    "        self.class_count = len(self.class_ids)\n",
    "        self.feature_count = len(self.likelihoods[0])\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    BernoulliMixtureModelJob().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HW6.7 driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "from ConvergingModelDriver import ConvergingModelDriver\n",
    "from BernoulliMixtureModelJob import BernoulliMixtureModelJob\n",
    "\n",
    "class BernoulliMixtureModelDriver(ConvergingModelDriver):\n",
    "\n",
    "    \"\"\"\n",
    "    For reproducibility, we'll start at everything evenly spaced at values\n",
    "    that are not too extreme (between 1/4 and 3/4)\n",
    "    \"\"\"\n",
    "    def get_initial_model(self):\n",
    "        \n",
    "        initial_model = {}\n",
    "        \n",
    "        class_ids = ['ClusterA', 'ClusterB', 'ClusterC', 'ClusterD']\n",
    "        priors = [1.0 / len(class_ids)] * len(class_ids)\n",
    "        \n",
    "        for class_id, prior in zip(class_ids, priors):\n",
    "            initial_model[class_id] = [prior]\n",
    "            initial_model[class_id].extend(numpy.random.random(1000))\n",
    "        \n",
    "        return initial_model        \n",
    "\n",
    "    \"\"\"\n",
    "    Return the job with a smoothing factor argument.\n",
    "    \"\"\"\n",
    "    def get_job(self, iteration_args):\n",
    "        smoothing_factor = 0.0001\n",
    "        \n",
    "        extra_args = ['--smoothing-factor=' + str(smoothing_factor)]\n",
    "        job_args = iteration_args + extra_args\n",
    "        \n",
    "        return BernoulliMixtureModelJob(args = job_args)\n",
    "\n",
    "    \"\"\"\n",
    "    Logs the model.\n",
    "    \"\"\"\n",
    "    def log_iteration(self, iteration, model, maximum_change):\n",
    "        class_priors = [\n",
    "            model[class_id][0] for class_id in ['ClusterA', 'ClusterB', 'ClusterC', 'ClusterD']\n",
    "        ]\n",
    "\n",
    "        print '%04d\\t%f\\t%f\\t%f\\t%f' % (\n",
    "            iteration, model['ClusterA'][0], model['ClusterB'][0], model['ClusterC'][0],\n",
    "            model['ClusterD'][0]\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__' and sys.argv[0].find('ipykernel') == -1:\n",
    "    driver = BernoulliMixtureModelDriver()\n",
    "    driver.run(sys.argv[1], sys.argv[2], sys.argv[3], float(sys.argv[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download HW4.5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As a test: use the same dataset from HW 4.5, the Tweet Dataset. \n",
    "Using this data, you will implement a 1000-dimensional EM-based Bernoulli Mixture Model  algorithm in MrJob on the users by their 1000-dimensional word stripes/vectors using K = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isfile('topUsers_features.txt'):\n",
    "    !wget --quiet https://www.dropbox.com/sh/5bex8l871t0bg3a/AAChDHmBbudx6E807bx5f_m0a/topUsers_Apr-Jul_2014_1000-words.txt\n",
    "    !cut -d',' -f 4- topUsers_Apr-Jul_2014_1000-words.txt > topUsers_features.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run HW6.7 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\t0.250000\t0.250000\t0.250000\t0.250000\n",
      "No handlers could be found for logger \"mrjob.local\"\n",
      "0001\t0.692000\t0.135000\t0.151000\t0.022000\n",
      "0002\t0.713000\t0.165000\t0.048000\t0.074000\n",
      "0003\t0.700000\t0.182000\t0.043000\t0.075000\n",
      "0004\t0.693000\t0.190000\t0.042000\t0.075000\n",
      "0005\t0.688000\t0.195000\t0.042000\t0.075000\n",
      "0006\t0.685000\t0.198000\t0.042000\t0.075000\n",
      "0007\t0.682000\t0.201000\t0.042000\t0.075000\n",
      "0008\t0.682000\t0.201000\t0.042000\t0.075000\n",
      "0009\t0.681000\t0.202000\t0.042000\t0.075000\n",
      "0010\t0.681000\t0.202000\t0.042000\t0.075000\n",
      "Converged in 10 iteration(s), which required 33.4158351421 second(s)\n"
     ]
    }
   ],
   "source": [
    "!python BernoulliMixtureModelDriver.py local topUsers_features.txt mrjob_65_output 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the original class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    752 0\r\n",
      "     91 1\r\n",
      "     54 2\r\n",
      "    103 3\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d',' -f 2 topUsers_Apr-Jul_2014_1000-words.txt | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run HW4.5 job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Repeat this experiment using your KMeans MRJob implementation fron HW4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report HW6.7 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Report the rand index score using the class code as ground truth label for both algorithms and comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 4,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
